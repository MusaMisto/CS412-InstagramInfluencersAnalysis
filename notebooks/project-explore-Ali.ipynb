{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBOlFYpnlr0N"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PM5EnXhLk6BL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import os\n",
        "\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgAdz_b8xp8w",
        "outputId": "14cd6ea6-4a61-4b22-f2a6-59088a78e58a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\itsmm\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#@title Turkish StopWords\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "turkish_stopwords = stopwords.words('turkish')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plt9-VkNmlmH"
      },
      "source": [
        "# Influencer Category Classification\n",
        "\n",
        "\n",
        "\n",
        "1.   Read Data\n",
        "2.   Preprocess Data\n",
        "3.   Prepare Model\n",
        "4.   Predict Test Data\n",
        "4.   Save outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8DeBh-b7lrEs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few rows of the training classification DataFrame:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>taskirancemal</td>\n",
              "      <td>mom and children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tam_kararinda</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spart4nn</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sosyalyiyiciler</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sonaydizdarahad</td>\n",
              "      <td>mom and children</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           user_id          category\n",
              "0    taskirancemal  mom and children\n",
              "1    tam_kararinda              food\n",
              "2         spart4nn              food\n",
              "3  sosyalyiyiciler              food\n",
              "4  sonaydizdarahad  mom and children"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the training directory\n",
        "training_dir = os.path.join(data_dir, 'training')\n",
        "\n",
        "# File path for 'train-classification.csv'\n",
        "train_classification_path = os.path.join(training_dir, 'train-classification.csv')\n",
        "\n",
        "# Step 2: Load Data Dynamically\n",
        "train_classification_df = pd.read_csv(train_classification_path)\n",
        "train_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n",
        "\n",
        "# Step 3: Unify Labels\n",
        "train_classification_df[\"category\"] = train_classification_df[\"category\"].apply(str.lower)\n",
        "\n",
        "# Step 4: Create User-to-Category Mapping\n",
        "username2_category = train_classification_df.set_index(\"user_id\").to_dict()[\"category\"]\n",
        "\n",
        "# Step 5: Verify Output\n",
        "print(\"First few rows of the training classification DataFrame:\")\n",
        "train_classification_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "SfD7BQ3hE5Jh",
        "outputId": "a67f08dd-ab3e-491f-bfe2-a14da0e961cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>art</th>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>entertainment</th>\n",
              "      <td>323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fashion</th>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>food</th>\n",
              "      <td>511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gaming</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>health and lifestyle</th>\n",
              "      <td>503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mom and children</th>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sports</th>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tech</th>\n",
              "      <td>346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>travel</th>\n",
              "      <td>294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      user_id\n",
              "category                     \n",
              "art                       191\n",
              "entertainment             323\n",
              "fashion                   299\n",
              "food                      511\n",
              "gaming                     13\n",
              "health and lifestyle      503\n",
              "mom and children          149\n",
              "sports                    113\n",
              "tech                      346\n",
              "travel                    294"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stats about the labels\n",
        "train_classification_df.groupby(\"category\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mhckiEfD2gg_",
        "outputId": "af451a4d-8825-4506-fb70-41a6ef845aaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'mom and children'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "username2_category[\"sonaydizdarahad\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GT_IcUM2nGBH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Training Users: 2741\n",
            "Number of Testing Users: 2674\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the training directory\n",
        "training_dir = os.path.join(data_dir, 'training')\n",
        "\n",
        "# File path for 'training-dataset.jsonl.gz'\n",
        "train_data_path = os.path.join(training_dir, 'training-dataset.jsonl.gz')\n",
        "\n",
        "# Step 2: Initialize Dictionaries for Data\n",
        "username2posts_train = dict()\n",
        "username2profile_train = dict()\n",
        "\n",
        "username2posts_test = dict()\n",
        "username2profile_test = dict()\n",
        "\n",
        "# Step 3: Process Data from 'training-dataset.jsonl.gz'\n",
        "with gzip.open(train_data_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for line in fh:\n",
        "        sample = json.loads(line)\n",
        "\n",
        "        profile = sample[\"profile\"]\n",
        "        username = profile.get(\"username\", \"\").strip()  # Handle missing or empty usernames\n",
        "        if not username:\n",
        "            continue  # Skip if username is missing or empty\n",
        "\n",
        "        if username in username2_category:\n",
        "            # Train data info\n",
        "            username2posts_train[username] = sample[\"posts\"]\n",
        "            username2profile_train[username] = profile\n",
        "        else:\n",
        "            # Test data info\n",
        "            username2posts_test[username] = sample[\"posts\"]\n",
        "            username2profile_test[username] = profile\n",
        "\n",
        "# Step 4: Verify Output\n",
        "print(f\"Number of Training Users: {len(username2posts_train)}\")\n",
        "print(f\"Number of Testing Users: {len(username2posts_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "djeF1GQ1oy3v",
        "outputId": "5c2ead24-d7d1-4df8-bec0-bf2152c76832"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>id</th>\n",
              "      <th>full_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>category_name</th>\n",
              "      <th>post_count</th>\n",
              "      <th>follower_count</th>\n",
              "      <th>following_count</th>\n",
              "      <th>is_business_account</th>\n",
              "      <th>is_private</th>\n",
              "      <th>...</th>\n",
              "      <th>business_category_name</th>\n",
              "      <th>overall_category_name</th>\n",
              "      <th>category_enum</th>\n",
              "      <th>is_verified_by_mv4b</th>\n",
              "      <th>is_regulated_c18</th>\n",
              "      <th>profile_pic_url</th>\n",
              "      <th>should_show_category</th>\n",
              "      <th>should_show_public_contacts</th>\n",
              "      <th>show_account_transparency_details</th>\n",
              "      <th>profile_picture_base64</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>deparmedya</td>\n",
              "      <td>3170700063</td>\n",
              "      <td>Depar Medya</td>\n",
              "      <td>#mediaplanning #mediabuying #sosyalmedya</td>\n",
              "      <td>Local business</td>\n",
              "      <td>None</td>\n",
              "      <td>1167</td>\n",
              "      <td>192</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>LOCAL</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://instagram.fsaw2-3.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     username          id    full_name  \\\n",
              "0  deparmedya  3170700063  Depar Medya   \n",
              "\n",
              "                                  biography   category_name post_count  \\\n",
              "0  #mediaplanning #mediabuying #sosyalmedya  Local business       None   \n",
              "\n",
              "  follower_count following_count is_business_account is_private  ...  \\\n",
              "0           1167             192                True      False  ...   \n",
              "\n",
              "  business_category_name overall_category_name category_enum  \\\n",
              "0                   None                  None         LOCAL   \n",
              "\n",
              "  is_verified_by_mv4b is_regulated_c18  \\\n",
              "0               False            False   \n",
              "\n",
              "                                     profile_pic_url should_show_category  \\\n",
              "0  https://instagram.fsaw2-3.fna.fbcdn.net/v/t51....                 True   \n",
              "\n",
              "  should_show_public_contacts show_account_transparency_details  \\\n",
              "0                        True                              True   \n",
              "\n",
              "                              profile_picture_base64  \n",
              "0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
              "\n",
              "[1 rows x 44 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Profile Dataframe\n",
        "train_profile_df = pd.DataFrame(username2profile_train).T.reset_index(drop=True)\n",
        "test_profile_df = pd.DataFrame(username2profile_test).T.reset_index(drop=True)\n",
        "\n",
        "train_profile_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "15tvVohUBHK9",
        "outputId": "15be2533-51b2-41e8-e0f2-26a44933dbae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>id</th>\n",
              "      <th>full_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>category_name</th>\n",
              "      <th>post_count</th>\n",
              "      <th>follower_count</th>\n",
              "      <th>following_count</th>\n",
              "      <th>is_business_account</th>\n",
              "      <th>is_private</th>\n",
              "      <th>...</th>\n",
              "      <th>business_category_name</th>\n",
              "      <th>overall_category_name</th>\n",
              "      <th>category_enum</th>\n",
              "      <th>is_verified_by_mv4b</th>\n",
              "      <th>is_regulated_c18</th>\n",
              "      <th>profile_pic_url</th>\n",
              "      <th>should_show_category</th>\n",
              "      <th>should_show_public_contacts</th>\n",
              "      <th>show_account_transparency_details</th>\n",
              "      <th>profile_picture_base64</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beyazyakaliyiz</td>\n",
              "      <td>8634457436</td>\n",
              "      <td>Selam Beyaz YakalÄ±</td>\n",
              "      <td>Beyaz yakalÄ±larÄ±n dÃ¼nyasÄ±na hoÅŸgeldiniz ðŸ˜€ðŸ˜€ðŸ˜€</td>\n",
              "      <td>Personal blog</td>\n",
              "      <td>None</td>\n",
              "      <td>1265</td>\n",
              "      <td>665</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>PERSONAL_BLOG</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://instagram.fist6-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         username          id           full_name  \\\n",
              "0  beyazyakaliyiz  8634457436  Selam Beyaz YakalÄ±   \n",
              "\n",
              "                                     biography  category_name post_count  \\\n",
              "0  Beyaz yakalÄ±larÄ±n dÃ¼nyasÄ±na hoÅŸgeldiniz ðŸ˜€ðŸ˜€ðŸ˜€  Personal blog       None   \n",
              "\n",
              "  follower_count following_count is_business_account is_private  ...  \\\n",
              "0           1265             665                True      False  ...   \n",
              "\n",
              "  business_category_name overall_category_name  category_enum  \\\n",
              "0                   None                  None  PERSONAL_BLOG   \n",
              "\n",
              "  is_verified_by_mv4b is_regulated_c18  \\\n",
              "0               False            False   \n",
              "\n",
              "                                     profile_pic_url should_show_category  \\\n",
              "0  https://instagram.fist6-1.fna.fbcdn.net/v/t51....                 True   \n",
              "\n",
              "  should_show_public_contacts show_account_transparency_details  \\\n",
              "0                        True                              True   \n",
              "\n",
              "                              profile_picture_base64  \n",
              "0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
              "\n",
              "[1 rows x 44 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_profile_df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Z5UY0eYLsoTr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Best Params: {'clf__C': 10, 'tfidf__ngram_range': (1, 1)}\n",
            "Best CV Accuracy: 0.6555628431684876\n",
            "Validation Accuracy: 0.6466302367941712\n",
            "Validation Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "                 art       0.20      0.11      0.14        38\n",
            "       entertainment       0.47      0.37      0.41        65\n",
            "             fashion       0.56      0.75      0.64        60\n",
            "                food       0.86      0.88      0.87       102\n",
            "              gaming       0.00      0.00      0.00         3\n",
            "health and lifestyle       0.67      0.72      0.69       100\n",
            "    mom and children       0.48      0.40      0.44        30\n",
            "              sports       0.74      0.74      0.74        23\n",
            "                tech       0.63      0.75      0.68        69\n",
            "              travel       0.72      0.66      0.69        59\n",
            "\n",
            "            accuracy                           0.65       549\n",
            "           macro avg       0.53      0.54      0.53       549\n",
            "        weighted avg       0.63      0.65      0.63       549\n",
            "\n",
            "Test predictions saved in output.json\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "\n",
        "def preprocess_text(text: str):\n",
        "    # lower casing Turkish text using .casefold() for robust case-insensitive comparison\n",
        "    text = text.casefold()\n",
        "    \n",
        "    # Remove URLs (http, https, www) \n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    \n",
        "    # Remove only some special characters and punctuation, \n",
        "    # but keep # and @, and do NOT remove emojis.\n",
        "    # We'll remove everything except letters, numbers, spaces, hashtags, mentions, and typical Turkish letters.\n",
        "    text = re.sub(r'[^a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼0-9\\s#@]+', '', text)\n",
        "\n",
        "    # Remove numbers if you wish (optional, you could keep them if they have meaning)\n",
        "    # text = re.sub(r'\\d+', '', text)\n",
        "    \n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "corpus = []\n",
        "\n",
        "# to keep the label order\n",
        "train_usernames = []\n",
        "\n",
        "for username, posts in username2posts_train.items():\n",
        "  train_usernames.append(username)\n",
        "\n",
        "  # aggregating the posts per user\n",
        "  cleaned_captions = []\n",
        "  for post in posts:\n",
        "    post_caption = post.get(\"caption\", \"\")\n",
        "    if post_caption is None:\n",
        "      continue\n",
        "\n",
        "    post_caption = preprocess_text(post_caption)\n",
        "\n",
        "    if post_caption != \"\":\n",
        "      cleaned_captions.append(post_caption)\n",
        "\n",
        "\n",
        "  # joining the posts of each user with a \\n\n",
        "  user_post_captions = \"\\n\".join(cleaned_captions)\n",
        "  corpus.append(user_post_captions)\n",
        "\n",
        "y_train = [username2_category.get(uname, \"NA\") for uname in train_usernames]\n",
        "\n",
        "##################################\n",
        "# New Pipeline Code (to replace old TF-IDF + NB code)\n",
        "##################################\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Step 1: Train-Validation Split for baseline\n",
        "x_train_texts, x_val_texts, y_train_labels, y_val_labels = train_test_split(\n",
        "    corpus, \n",
        "    y_train, \n",
        "    test_size=0.2, \n",
        "    stratify=y_train, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Step 2: Create a pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        stop_words=turkish_stopwords,\n",
        "        ngram_range=(1,2),         # try bigrams\n",
        "        max_features=5000\n",
        "    )),\n",
        "    ('clf', LogisticRegression(\n",
        "        class_weight='balanced',   # handle class imbalance\n",
        "        solver='liblinear',\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Step 3: Hyperparameter grid\n",
        "param_grid = {\n",
        "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
        "    'clf__C': [0.01, 0.1, 1, 10]\n",
        "}\n",
        "\n",
        "# Step 4: Grid Search\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline, \n",
        "    param_grid, \n",
        "    scoring='accuracy', \n",
        "    cv=3,  # 3-fold cross validation\n",
        "    verbose=1, \n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search.fit(x_train_texts, y_train_labels)\n",
        "\n",
        "print(\"Best Params:\", grid_search.best_params_)\n",
        "print(\"Best CV Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Step 5: Evaluate on validation data\n",
        "best_pipeline = grid_search.best_estimator_\n",
        "y_val_pred = best_pipeline.predict(x_val_texts)\n",
        "val_acc = accuracy_score(y_val_labels, y_val_pred)\n",
        "print(\"Validation Accuracy:\", val_acc)\n",
        "print(\"Validation Classification Report:\\n\", \n",
        "      classification_report(y_val_labels, y_val_pred, zero_division=0))\n",
        "\n",
        "##################################\n",
        "# New Test Prediction Code\n",
        "##################################\n",
        "test_corpus = []\n",
        "test_usernames = []\n",
        "\n",
        "for username, posts in username2posts_test.items():\n",
        "    test_usernames.append(username)\n",
        "    cleaned_captions = []\n",
        "    for post in posts:\n",
        "        post_caption = post.get(\"caption\", \"\")\n",
        "        if post_caption is None:\n",
        "            continue\n",
        "        cleaned_captions.append(preprocess_text(post_caption))\n",
        "    user_post_captions = \"\\n\".join(cleaned_captions)\n",
        "    test_corpus.append(user_post_captions)\n",
        "\n",
        "# Predict using the best pipeline found by grid search\n",
        "test_pred = best_pipeline.predict(test_corpus)\n",
        "\n",
        "# Then create your output dictionary\n",
        "output = {}\n",
        "for index, uname in enumerate(test_usernames):\n",
        "    output[uname] = test_pred[index]\n",
        "\n",
        "with open(\"output.json\", \"w\") as of:\n",
        "    json.dump(output, of, indent=4)\n",
        "\n",
        "print(\"Test predictions saved in output.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Q-BcPjw_39aP"
      },
      "outputs": [],
      "source": [
        "# Making sure everything is fine\n",
        "assert y_train.count(\"NA\") == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF Feature Columns:\n",
            "['abdullah' 'abone' 'about' ... 'ÅŸÄ±k' 'ÅŸÄ±klÄ±k' 'ÅŸÄ±klÄ±ÄŸÄ±']\n"
          ]
        }
      ],
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(\"TF-IDF Feature Columns:\")\n",
        "print(feature_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "xa4v453o0Mo_",
        "outputId": "4787ecd7-ba6f-44aa-fa0a-cdaf39d33d3a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abdullah</th>\n",
              "      <th>abone</th>\n",
              "      <th>about</th>\n",
              "      <th>acele</th>\n",
              "      <th>acil</th>\n",
              "      <th>activities</th>\n",
              "      <th>acÄ±</th>\n",
              "      <th>ad</th>\n",
              "      <th>ada</th>\n",
              "      <th>adam</th>\n",
              "      <th>...</th>\n",
              "      <th>ÅŸubemiz</th>\n",
              "      <th>ÅŸubesi</th>\n",
              "      <th>ÅŸÃ¶len</th>\n",
              "      <th>ÅŸÃ¶leni</th>\n",
              "      <th>ÅŸÃ¶yle</th>\n",
              "      <th>ÅŸÃ¼kranla</th>\n",
              "      <th>ÅŸÃ¼kÃ¼r</th>\n",
              "      <th>ÅŸÄ±k</th>\n",
              "      <th>ÅŸÄ±klÄ±k</th>\n",
              "      <th>ÅŸÄ±klÄ±ÄŸÄ±</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.050596</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows Ã— 5000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   abdullah  abone  about  acele  acil  activities  acÄ±   ad  ada  adam  ...  \\\n",
              "0       0.0    0.0    0.0    0.0   0.0         0.0  0.0  0.0  0.0   0.0  ...   \n",
              "\n",
              "   ÅŸubemiz  ÅŸubesi  ÅŸÃ¶len  ÅŸÃ¶leni  ÅŸÃ¶yle  ÅŸÃ¼kranla  ÅŸÃ¼kÃ¼r       ÅŸÄ±k  ÅŸÄ±klÄ±k  \\\n",
              "0      0.0     0.0    0.0     0.0    0.0       0.0    0.0  0.050596     0.0   \n",
              "\n",
              "   ÅŸÄ±klÄ±ÄŸÄ±  \n",
              "0      0.0  \n",
              "\n",
              "[1 rows x 5000 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tfidf = pd.DataFrame(x_post_train.toarray(), columns=feature_names)\n",
        "df_tfidf.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i9xO_ZX1NXC",
        "outputId": "15c76222-630d-4c3c-9ba5-96a44af78a9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2741, 5000)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tfidf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ehUT3JSFz7yo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2192, 5000)\n",
            "(549, 5000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(df_tfidf, y_train, test_size=0.2, stratify=y_train)\n",
        "\n",
        "print(x_train.shape)\n",
        "\n",
        "print(x_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khu0eryhNZNN"
      },
      "source": [
        "# Naive Base Classifier\n",
        "\n",
        "### Now we can pass the numerical values to a classifier, Let's try Naive Base!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "rdHIvFrSCMZj",
        "outputId": "043e1aaf-0e8b-4b20-8a32-c27298d253ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.656934306569343\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "                 art       0.88      0.09      0.17       153\n",
            "       entertainment       0.63      0.56      0.59       258\n",
            "             fashion       0.77      0.73      0.75       239\n",
            "                food       0.82      0.89      0.85       409\n",
            "              gaming       0.00      0.00      0.00        10\n",
            "health and lifestyle       0.49      0.85      0.62       402\n",
            "    mom and children       0.92      0.09      0.17       119\n",
            "              sports       1.00      0.11      0.20        90\n",
            "                tech       0.77      0.81      0.79       277\n",
            "              travel       0.59      0.69      0.63       235\n",
            "\n",
            "            accuracy                           0.66      2192\n",
            "           macro avg       0.69      0.48      0.48      2192\n",
            "        weighted avg       0.71      0.66      0.62      2192\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "model = MultinomialNB()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "#@title Train Data\n",
        "y_train_pred = model.predict(x_train)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyY9aFtGDrAj",
        "outputId": "e44c466d-6bf0-4556-ad4b-7c7111ad2835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6029143897996357\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "                 art       0.00      0.00      0.00        38\n",
            "       entertainment       0.57      0.45      0.50        65\n",
            "             fashion       0.65      0.65      0.65        60\n",
            "                food       0.77      0.87      0.82       102\n",
            "              gaming       0.00      0.00      0.00         3\n",
            "health and lifestyle       0.46      0.84      0.59       100\n",
            "    mom and children       1.00      0.03      0.06        30\n",
            "              sports       0.00      0.00      0.00        23\n",
            "                tech       0.75      0.80      0.77        69\n",
            "              travel       0.53      0.58      0.55        59\n",
            "\n",
            "            accuracy                           0.60       549\n",
            "           macro avg       0.47      0.42      0.40       549\n",
            "        weighted avg       0.57      0.60      0.55       549\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Validation Data\n",
        "y_val_pred = model.predict(x_val)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_val_pred, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU6aALFaCMkd",
        "outputId": "83913a4f-45bc-4e1a-e069-06d452f31255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ozhotelstr\n",
            "elleturkiye\n",
            "sozerinsaatorhangazi\n",
            "sanliurfapiazzaavym\n",
            "rusanozden\n",
            "*****\n",
            "['ozhotelstr', 'elleturkiye', 'sozerinsaatorhangazi', 'sanliurfapiazzaavym', 'rusanozden']\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the testing directory\n",
        "testing_dir = os.path.join(data_dir, 'testing')\n",
        "\n",
        "# File path for 'test-classification-round1.dat'\n",
        "test_data_path = os.path.join(testing_dir, 'test-classification-round1.dat')\n",
        "\n",
        "# Step 2: Preview First 5 Lines of the Test File\n",
        "with open(test_data_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for i, line in enumerate(fh):\n",
        "        print(line.strip())\n",
        "        if i == 4:  # Print only the first 5 lines\n",
        "            break\n",
        "\n",
        "print(\"*****\")\n",
        "\n",
        "# Step 3: Extract Usernames from Test Data\n",
        "test_unames = []\n",
        "with open(test_data_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for line in fh:\n",
        "        test_unames.append(line.strip())\n",
        "\n",
        "# Step 4: Verify Output\n",
        "print(test_unames[:5])  # Display the first 5 usernames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqLF4LN8GqKm",
        "outputId": "779e32d6-a7be-4a03-d6c9-7f601b68cdbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "screenname\n"
          ]
        }
      ],
      "source": [
        "x_test = []\n",
        "\n",
        "for uname in test_unames:\n",
        "  try:\n",
        "    index = test_usernames.index(uname)\n",
        "    x_test.append(x_post_test[index].toarray()[0])\n",
        "  except Exception as e:\n",
        "    try:\n",
        "      index = train_usernames.index(uname)\n",
        "      x_test.append(x_post_train[index].toarray()[0])\n",
        "    except Exception as e:\n",
        "      print(uname)\n",
        "\n",
        "\n",
        "test_unames.remove(\"screenname\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "c2rswpw7IqGc",
        "outputId": "f6616829-1caa-41a2-c65f-72d82f4539c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abdullah</th>\n",
              "      <th>abone</th>\n",
              "      <th>about</th>\n",
              "      <th>acele</th>\n",
              "      <th>acil</th>\n",
              "      <th>activities</th>\n",
              "      <th>acÄ±</th>\n",
              "      <th>ad</th>\n",
              "      <th>ada</th>\n",
              "      <th>adam</th>\n",
              "      <th>...</th>\n",
              "      <th>ÅŸubemiz</th>\n",
              "      <th>ÅŸubesi</th>\n",
              "      <th>ÅŸÃ¶len</th>\n",
              "      <th>ÅŸÃ¶leni</th>\n",
              "      <th>ÅŸÃ¶yle</th>\n",
              "      <th>ÅŸÃ¼kranla</th>\n",
              "      <th>ÅŸÃ¼kÃ¼r</th>\n",
              "      <th>ÅŸÄ±k</th>\n",
              "      <th>ÅŸÄ±klÄ±k</th>\n",
              "      <th>ÅŸÄ±klÄ±ÄŸÄ±</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013628</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.025994</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.011087</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows Ã— 5000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   abdullah  abone  about  acele  acil  activities  acÄ±   ad  ada  adam  ...  \\\n",
              "0       0.0    0.0    0.0    0.0   0.0    0.013628  0.0  0.0  0.0   0.0  ...   \n",
              "1       0.0    0.0    0.0    0.0   0.0    0.000000  0.0  0.0  0.0   0.0  ...   \n",
              "\n",
              "   ÅŸubemiz  ÅŸubesi  ÅŸÃ¶len  ÅŸÃ¶leni     ÅŸÃ¶yle  ÅŸÃ¼kranla  ÅŸÃ¼kÃ¼r       ÅŸÄ±k  \\\n",
              "0      0.0     0.0    0.0     0.0  0.000000       0.0    0.0  0.000000   \n",
              "1      0.0     0.0    0.0     0.0  0.025994       0.0    0.0  0.011087   \n",
              "\n",
              "   ÅŸÄ±klÄ±k  ÅŸÄ±klÄ±ÄŸÄ±  \n",
              "0     0.0      0.0  \n",
              "1     0.0      0.0  \n",
              "\n",
              "[2 rows x 5000 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test = pd.DataFrame(np.array(x_test), columns=feature_names)\n",
        "df_test.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "gUsUQtpMKTse"
      },
      "outputs": [],
      "source": [
        "test_pred = model.predict(df_test)\n",
        "\n",
        "output = dict()\n",
        "for index, uname in enumerate(test_unames):\n",
        "  output[uname] = test_pred[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "W-NJSnyxIrw4"
      },
      "outputs": [],
      "source": [
        "with open(\"output.json\", \"w\") as of:\n",
        "  json.dump(output, of, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC7KXsQZL7Kp"
      },
      "source": [
        "# Like Count Prediction\n",
        "\n",
        "\n",
        "Here, we use the average like_count of the user's previous posts to predict each post's like_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nolpagasSuBq"
      },
      "outputs": [],
      "source": [
        "def predict_like_count(username, current_post=None):\n",
        "  def get_avg_like_count(posts:list):\n",
        "    total = 0.\n",
        "    for post in posts:\n",
        "      if current_post is not None and post[\"id\"] == current_post[\"id\"]:\n",
        "        continue\n",
        "\n",
        "      like_count = post.get(\"like_count\", 0)\n",
        "      if like_count is None:\n",
        "        like_count = 0\n",
        "      total += like_count\n",
        "\n",
        "    if len(posts) == 0:\n",
        "      return 0.\n",
        "\n",
        "    return total / len(posts)\n",
        "\n",
        "  if username in username2posts_train:\n",
        "    return get_avg_like_count(username2posts_train[username])\n",
        "  elif username in username2posts_test:\n",
        "    return get_avg_like_count(username2posts_test[username])\n",
        "  else:\n",
        "    print(f\"No data available for {username}\")\n",
        "    return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ZNWTjLZ6XAuj"
      },
      "outputs": [],
      "source": [
        "def log_mse_like_counts(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculate the Log Mean Squared Error (Log MSE) for like counts (log(like_count + 1)).\n",
        "\n",
        "  Parameters:\n",
        "  - y_true: array-like, actual like counts\n",
        "  - y_pred: array-like, predicted like counts\n",
        "\n",
        "  Returns:\n",
        "  - log_mse: float, Log Mean Squared Error\n",
        "  \"\"\"\n",
        "  # Ensure inputs are numpy arrays\n",
        "  y_true = np.array(y_true)\n",
        "  y_pred = np.array(y_pred)\n",
        "\n",
        "  # Log transformation: log(like_count + 1)\n",
        "  log_y_true = np.log1p(y_true)\n",
        "  log_y_pred = np.log1p(y_pred)\n",
        "\n",
        "  # Compute squared errors\n",
        "  squared_errors = (log_y_true - log_y_pred) ** 2\n",
        "\n",
        "  # Return the mean of squared errors\n",
        "  return np.mean(squared_errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1jETdAuXA0H",
        "outputId": "871164d0-74fb-49cd-ea77-b8a3e0793e81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log MSE Train= 1.2271047744059362\n"
          ]
        }
      ],
      "source": [
        "#@title Train Dataset evaluation\n",
        "\n",
        "y_like_count_train_true = []\n",
        "y_like_count_train_pred = []\n",
        "for uname, posts in username2posts_train.items():\n",
        "  for post in posts:\n",
        "    pred_val = predict_like_count(uname, post)\n",
        "    true_val = post.get(\"like_count\", 0)\n",
        "    if true_val is None:\n",
        "      true_val = 0\n",
        "\n",
        "    y_like_count_train_true.append(true_val)\n",
        "    y_like_count_train_pred.append(pred_val)\n",
        "\n",
        "print(f\"Log MSE Train= {log_mse_like_counts(y_like_count_train_true, y_like_count_train_pred)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "F02V1wO-WBMV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed data saved to: c:\\Users\\itsmm\\OneDrive\\Desktop\\CS412\\CS412-InstagramInfluencersAnalysis\\data\\output\\test-regression-round1.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the testing directory\n",
        "testing_dir = os.path.join(data_dir, 'testing')\n",
        "\n",
        "# File path for 'test-regression-round1.jsonl'\n",
        "test_dataset_path = os.path.join(testing_dir, 'test-regression-round1.jsonl')\n",
        "\n",
        "# File path for output\n",
        "output_dir = os.path.join(data_dir, 'output')\n",
        "os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
        "output_file_path = os.path.join(output_dir, 'test-regression-round1.jsonl')\n",
        "\n",
        "# Step 2: Process the Test Dataset\n",
        "to_predict_like_counts_usernames = []\n",
        "output_list = []\n",
        "\n",
        "with open(test_dataset_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for line in fh:\n",
        "        sample = json.loads(line)\n",
        "\n",
        "        # Perform prediction\n",
        "        pred_val = predict_like_count(sample[\"username\"])  # Ensure `predict_like_count` is defined\n",
        "        sample[\"like_count\"] = int(pred_val)\n",
        "        output_list.append(sample)\n",
        "\n",
        "# Step 3: Save the Output to a File\n",
        "with open(output_file_path, \"wt\", encoding=\"utf-8\") as of:\n",
        "    json.dump(output_list, of)\n",
        "\n",
        "# Step 4: Output Verification\n",
        "print(f\"Processed data saved to: {output_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blI2SqvvvOF8",
        "outputId": "fe1e72e3-3ad0-486d-d054-3e90e8c66669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'caption': 'KOZA 2023 2.si Damlaâ€™nÄ±n koleksiyonu, Latincede â€˜Memento Moriâ€™ '\n",
            "             'olarak bilinen â€˜Ã¶lÃ¼mlÃ¼ olduÄŸunu hatÄ±rlaâ€™ anlamÄ±ndaki ifadeden '\n",
            "             'esinleniyor. Koleksiyon, hayatÄ±n ve Ã¶lÃ¼mÃ¼n, para, iÅŸÃ§i, kral ve '\n",
            "             'kraliÃ§e kavramlarÄ± Ã¼zerinden yaratÄ±cÄ± gÃ¶rÃ¼nÃ¼mlerle bir araya '\n",
            "             'getirilmesini amaÃ§lÄ±yor. Ã–lÃ¼m sembollerinden esinlenen desenler '\n",
            "             'kullanan Damla, â€œkaÄŸÄ±t parÃ§asÄ±ndan ibaret olmakâ€ kavramÄ±nÄ± '\n",
            "             'vurguluyor. Koleksiyon, yaÅŸamÄ±n ve Ã¶lÃ¼mÃ¼n aynÄ± anda ifade '\n",
            "             'edilmesini hedefliyor; kÄ±rmÄ±zÄ± ve mavi Ä±ÅŸÄ±klarla veya '\n",
            "             'gÃ¶zlÃ¼klerle gÃ¶rÃ¼len hologram efekti kullanÄ±larak bu konsept '\n",
            "             'sahneye taÅŸÄ±nÄ±yor. KÄ±rmÄ±zÄ± renk Ã¶lÃ¼mÃ¼, mavi ise yaÅŸamÄ± '\n",
            "             'simgeliyor. Koleksiyon, ofis giyimlerinden esinlenerek '\n",
            "             'kravatlar, gÃ¶mlekler ve evrak Ã§antalarÄ± iÃ§eriyor. Klasik sivri '\n",
            "             'burun Ã§izmelerin Ã¼zerine spor ayakkabÄ±larÄ±n Ã¼st yÃ¼zeyi '\n",
            "             'yerleÅŸtirilerek, iÅŸ dÃ¼nyasÄ±nÄ±n koÅŸuÅŸturmasÄ± ve cenaze '\n",
            "             'temalarÄ±nÄ±n aynÄ± anda ifade edilmesi amaÃ§lanÄ±yor. Para kazanma '\n",
            "             'arzusu, kÄ±rmÄ±zÄ± zambak desenleri ve bÃ¼yÃ¼k mÃ¼cevher gÃ¶rÃ¼nÃ¼mleri '\n",
            "             'ile koleksiyon tamamlanÄ±yor.\\n'\n",
            "             '\\n'\n",
            "             'Tebrikler Damla!\\n'\n",
            "             '\\n'\n",
            "             '#GencModaTasarimcilari #Koza2023 #KozaYarismasi '\n",
            "             '#TasarimYarismasi #Moda #Fashion #ModaTasarÄ±mÄ±',\n",
            "  'comments_count': 2,\n",
            "  'id': '18144550534306740',\n",
            "  'like_count': 158,\n",
            "  'media_type': 'CAROUSEL_ALBUM',\n",
            "  'media_url': 'https://scontent-sof1-1.cdninstagram.com/v/t51.29350-15/397997154_1016992459537522_4925783512176260397_n.jpg?_nc_cat=106&ccb=1-7&_nc_sid=c4dd86&_nc_ohc=7V_eObkFeK4AX-LMtsK&_nc_ht=scontent-sof1-1.cdninstagram.com&edm=AL-3X8kEAAAA&oh=00_AfDEqDhzaTO3ezV-veT6cJFCOcAEyeVzHR6si9n33N6G5A&oe=6551B6B9',\n",
            "  'timestamp': '2023-11-02 15:49:22',\n",
            "  'username': 'kozayarismasi'},\n",
            " {'caption': 'TÃ¼m TÃ¼rkiye ve Avrupaâ€™ya sevkiyatlarÄ±mÄ±z aralÄ±ksÄ±z devam ediyor! '\n",
            "             'AracÄ±mÄ±z Bursaâ€™dan Orduâ€™ya mÃ¼ÅŸterimizin Ã¼rÃ¼nleri iÃ§in yola '\n",
            "             'Ã§Ä±kÄ±yor.\\n'\n",
            "             '\\n'\n",
            "             'ðŸ‘‰Tuna Mah. Etibank Cad. No:134 Osmangazi/BURSA\\n'\n",
            "             '\\n'\n",
            "             'www.celikbeymobilya.com sitemizden tÃ¼m modelleri '\n",
            "             'inceleyebilirsiniz. \\n'\n",
            "             '\\n'\n",
            "             '#bursa #almanya #fransa',\n",
            "  'comments_count': 0,\n",
            "  'id': '17995331788956693',\n",
            "  'like_count': 99,\n",
            "  'media_type': 'VIDEO',\n",
            "  'media_url': 'https://scontent-sof1-2.cdninstagram.com/o1/v/t16/f1/m82/BF4767CB85BDFB8ADCCCA8F15B8C20B5_video_dashinit.mp4?efg=eyJ2ZW5jb2RlX3RhZyI6InZ0c192b2RfdXJsZ2VuLmNsaXBzLnVua25vd24tQzMuNzIwLmRhc2hfYmFzZWxpbmVfMV92MSJ9&_nc_ht=scontent-sof1-2.cdninstagram.com&_nc_cat=110&vs=1259525061418244_1441854817&_nc_vs=HBksFQIYT2lnX3hwdl9yZWVsc19wZXJtYW5lbnRfcHJvZC9CRjQ3NjdDQjg1QkRGQjhBRENDQ0E4RjE1QjhDMjBCNV92aWRlb19kYXNoaW5pdC5tcDQVAALIAQAVAhg6cGFzc3Rocm91Z2hfZXZlcnN0b3JlL0dBRWdfaFZfcDVCYk5HZ0NBQTlzVURvZW5mZ3FicV9FQUFBRhUCAsgBACgAGAAbAYgHdXNlX29pbAExFQAAJvS3uOiQ0P8%2FFQIoAkMzLBdAJO%2Bdsi0OVhgSZGFzaF9iYXNlbGluZV8xX3YxEQB1AAA%3D&ccb=9-4&oh=00_AfAm22JssMPaUlQe3rpYsFWBhFb5mUgolTCdhV0Xgm4AnA&oe=6556A482&_nc_sid=1d576d&_nc_rid=cd9a998e44',\n",
            "  'timestamp': '2023-08-19 13:46:02',\n",
            "  'username': 'celikbeymobilya'},\n",
            " {'caption': 'ðŸ¤©\\n'\n",
            "             '\\n'\n",
            "             '.\\n'\n",
            "             '.\\n'\n",
            "             'Daha FazlasÄ± Ä°Ã§in BeÄŸenmeyi ve Takip Etmeyi UnutmayÄ±n\\n'\n",
            "             '.\\n'\n",
            "             'girisimci_muhendis âœ…\\n'\n",
            "             '.\\n'\n",
            "             'ðŸ“£Bu Bilgi HakkÄ±nda Ne DÃ¼ÅŸÃ¼nÃ¼yorsunuz.\\n'\n",
            "             '.\\n'\n",
            "             'âœ…GÃ¶rmesini Ä°stediÄŸin ArkadaÅŸÄ±nÄ± Etiketle.\\n'\n",
            "             '.\\n'\n",
            "             'ðŸ””GÃ¶nderi Bildirimlerini AÃ§arak, Bilgileri AnÄ±nda '\n",
            "             'Ã–ÄŸrenebilirsiniz.\\n'\n",
            "             '\\n'\n",
            "             '.\\n'\n",
            "             '\\n'\n",
            "             'Source: Unknown\\n'\n",
            "             'Dm for Credit or removal\\n'\n",
            "             '.\\n'\n",
            "             '.............................................................\\n'\n",
            "             'All rights and credits reserved to the respective owner(s). If '\n",
            "             'you are the main copyright owner rather than the one mentioned '\n",
            "             'here of this content, contact me to claim credit or content '\n",
            "             'removal',\n",
            "  'comments_count': 75,\n",
            "  'id': '18302703232191518',\n",
            "  'like_count': 1224,\n",
            "  'media_type': 'VIDEO',\n",
            "  'media_url': None,\n",
            "  'timestamp': '2023-10-02 06:53:33',\n",
            "  'username': 'girisimci_muhendis'}]\n"
          ]
        }
      ],
      "source": [
        "# output_list first 3 items\n",
        "pprint(output_list[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYP0TzdoGbpt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
