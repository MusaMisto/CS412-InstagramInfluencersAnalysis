{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBOlFYpnlr0N"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "PM5EnXhLk6BL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\itsmm\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "import os\n",
        "import gzip\n",
        "import json\n",
        "from pprint import pprint\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Turkish StopWords\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "turkish_stopwords = stopwords.words('turkish')\n",
        "\n",
        "import emoji\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plt9-VkNmlmH"
      },
      "source": [
        "# Influencer Category Classification\n",
        "\n",
        "\n",
        "\n",
        "1.   Read Data\n",
        "2.   Preprocess Data\n",
        "3.   Prepare Model\n",
        "4.   Predict Test Data\n",
        "4.   Save outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "8DeBh-b7lrEs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few rows of the training classification DataFrame:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>taskirancemal</td>\n",
              "      <td>mom and children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tam_kararinda</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spart4nn</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sosyalyiyiciler</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sonaydizdarahad</td>\n",
              "      <td>mom and children</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           user_id          category\n",
              "0    taskirancemal  mom and children\n",
              "1    tam_kararinda              food\n",
              "2         spart4nn              food\n",
              "3  sosyalyiyiciler              food\n",
              "4  sonaydizdarahad  mom and children"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the training directory\n",
        "training_dir = os.path.join(data_dir, 'training')\n",
        "\n",
        "# File path for 'train-classification.csv'\n",
        "train_classification_path = os.path.join(training_dir, 'train-classification.csv')\n",
        "\n",
        "# Step 2: Load Data Dynamically\n",
        "train_classification_df = pd.read_csv(train_classification_path)\n",
        "train_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n",
        "\n",
        "# Step 3: Unify Labels\n",
        "train_classification_df[\"category\"] = train_classification_df[\"category\"].apply(str.lower)\n",
        "\n",
        "# Step 4: Create User-to-Category Mapping\n",
        "username2_category = train_classification_df.set_index(\"user_id\").to_dict()[\"category\"]\n",
        "\n",
        "# Step 5: Verify Output\n",
        "print(\"First few rows of the training classification DataFrame:\")\n",
        "train_classification_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "SfD7BQ3hE5Jh",
        "outputId": "a67f08dd-ab3e-491f-bfe2-a14da0e961cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tech\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>art</th>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>entertainment</th>\n",
              "      <td>323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fashion</th>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>food</th>\n",
              "      <td>511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gaming</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>health and lifestyle</th>\n",
              "      <td>503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mom and children</th>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sports</th>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tech</th>\n",
              "      <td>346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>travel</th>\n",
              "      <td>294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      user_id\n",
              "category                     \n",
              "art                       191\n",
              "entertainment             323\n",
              "fashion                   299\n",
              "food                      511\n",
              "gaming                     13\n",
              "health and lifestyle      503\n",
              "mom and children          149\n",
              "sports                    113\n",
              "tech                      346\n",
              "travel                    294"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(username2_category[\"kod8net\"] + \"\\n\")\n",
        "\n",
        "# stats about the labels\n",
        "train_classification_df.groupby(\"category\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "GT_IcUM2nGBH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Training Users: 2741\n",
            "Number of Testing Users: 2674\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the training directory\n",
        "training_dir = os.path.join(data_dir, 'training')\n",
        "\n",
        "# File path for 'training-dataset.jsonl.gz'\n",
        "train_data_path = os.path.join(training_dir, 'training-dataset.jsonl.gz')\n",
        "\n",
        "# Step 2: Initialize Dictionaries for Data\n",
        "username2posts_train = dict()\n",
        "username2profile_train = dict()\n",
        "\n",
        "username2posts_test = dict()\n",
        "username2profile_test = dict()\n",
        "\n",
        "# Step 3: Process Data from 'training-dataset.jsonl.gz'\n",
        "with gzip.open(train_data_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for line in fh:\n",
        "        sample = json.loads(line)\n",
        "\n",
        "        profile = sample[\"profile\"]\n",
        "        username = profile.get(\"username\", \"\").strip()  # Handle missing or empty usernames\n",
        "        if not username:\n",
        "            continue  # Skip if username is missing or empty\n",
        "\n",
        "        if username in username2_category:\n",
        "            # Train data info\n",
        "            username2posts_train[username] = sample[\"posts\"]\n",
        "            username2profile_train[username] = profile\n",
        "        else:\n",
        "            # Test data info\n",
        "            username2posts_test[username] = sample[\"posts\"]\n",
        "            username2profile_test[username] = profile\n",
        "\n",
        "# Step 4: Verify Output\n",
        "print(f\"Number of Training Users: {len(username2posts_train)}\")\n",
        "print(f\"Number of Testing Users: {len(username2posts_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "djeF1GQ1oy3v",
        "outputId": "5c2ead24-d7d1-4df8-bec0-bf2152c76832"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>id</th>\n",
              "      <th>full_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>category_name</th>\n",
              "      <th>post_count</th>\n",
              "      <th>follower_count</th>\n",
              "      <th>following_count</th>\n",
              "      <th>is_business_account</th>\n",
              "      <th>is_private</th>\n",
              "      <th>...</th>\n",
              "      <th>business_category_name</th>\n",
              "      <th>overall_category_name</th>\n",
              "      <th>category_enum</th>\n",
              "      <th>is_verified_by_mv4b</th>\n",
              "      <th>is_regulated_c18</th>\n",
              "      <th>profile_pic_url</th>\n",
              "      <th>should_show_category</th>\n",
              "      <th>should_show_public_contacts</th>\n",
              "      <th>show_account_transparency_details</th>\n",
              "      <th>profile_picture_base64</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>deparmedya</td>\n",
              "      <td>3170700063</td>\n",
              "      <td>Depar Medya</td>\n",
              "      <td>#mediaplanning #mediabuying #sosyalmedya</td>\n",
              "      <td>Local business</td>\n",
              "      <td>None</td>\n",
              "      <td>1167</td>\n",
              "      <td>192</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>LOCAL</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://instagram.fsaw2-3.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kafesfirin</td>\n",
              "      <td>266439571</td>\n",
              "      <td>KAFES FIRIN</td>\n",
              "      <td>📍Söğütözü📍FTZ AVM\\n🛒Ankara macro▲center v...</td>\n",
              "      <td>Brand</td>\n",
              "      <td>None</td>\n",
              "      <td>11997</td>\n",
              "      <td>17</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>BRAND</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://instagram.fada1-13.fna.fbcdn.net/v/t51...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     username          id    full_name  \\\n",
              "0  deparmedya  3170700063  Depar Medya   \n",
              "1  kafesfirin   266439571  KAFES FIRIN   \n",
              "\n",
              "                                           biography   category_name  \\\n",
              "0           #mediaplanning #mediabuying #sosyalmedya  Local business   \n",
              "1  📍Söğütözü📍FTZ AVM\\n🛒Ankara macro▲center v...           Brand   \n",
              "\n",
              "  post_count follower_count following_count is_business_account is_private  \\\n",
              "0       None           1167             192                True      False   \n",
              "1       None          11997              17                True      False   \n",
              "\n",
              "   ... business_category_name overall_category_name category_enum  \\\n",
              "0  ...                   None                  None         LOCAL   \n",
              "1  ...                   None                  None         BRAND   \n",
              "\n",
              "  is_verified_by_mv4b is_regulated_c18  \\\n",
              "0               False            False   \n",
              "1               False            False   \n",
              "\n",
              "                                     profile_pic_url should_show_category  \\\n",
              "0  https://instagram.fsaw2-3.fna.fbcdn.net/v/t51....                 True   \n",
              "1  https://instagram.fada1-13.fna.fbcdn.net/v/t51...                 True   \n",
              "\n",
              "  should_show_public_contacts show_account_transparency_details  \\\n",
              "0                        True                              True   \n",
              "1                        True                              True   \n",
              "\n",
              "                              profile_picture_base64  \n",
              "0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
              "1  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
              "\n",
              "[2 rows x 44 columns]"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Profile Dataframe\n",
        "train_profile_df = pd.DataFrame(username2profile_train).T.reset_index(drop=True)\n",
        "test_profile_df = pd.DataFrame(username2profile_test).T.reset_index(drop=True)\n",
        "\n",
        "train_profile_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "15tvVohUBHK9",
        "outputId": "15be2533-51b2-41e8-e0f2-26a44933dbae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>id</th>\n",
              "      <th>full_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>category_name</th>\n",
              "      <th>post_count</th>\n",
              "      <th>follower_count</th>\n",
              "      <th>following_count</th>\n",
              "      <th>is_business_account</th>\n",
              "      <th>is_private</th>\n",
              "      <th>...</th>\n",
              "      <th>business_category_name</th>\n",
              "      <th>overall_category_name</th>\n",
              "      <th>category_enum</th>\n",
              "      <th>is_verified_by_mv4b</th>\n",
              "      <th>is_regulated_c18</th>\n",
              "      <th>profile_pic_url</th>\n",
              "      <th>should_show_category</th>\n",
              "      <th>should_show_public_contacts</th>\n",
              "      <th>show_account_transparency_details</th>\n",
              "      <th>profile_picture_base64</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beyazyakaliyiz</td>\n",
              "      <td>8634457436</td>\n",
              "      <td>Selam Beyaz Yakalı</td>\n",
              "      <td>Beyaz yakalıların dünyasına hoşgeldiniz 😀😀😀</td>\n",
              "      <td>Personal blog</td>\n",
              "      <td>None</td>\n",
              "      <td>1265</td>\n",
              "      <td>665</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>PERSONAL_BLOG</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://instagram.fist6-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>totalenergies_istasyonlari</td>\n",
              "      <td>7066643793</td>\n",
              "      <td>TotalEnergies İstasyonları</td>\n",
              "      <td>TotalEnergies İstasyonları resmi Instagram hes...</td>\n",
              "      <td>Energy Company</td>\n",
              "      <td>None</td>\n",
              "      <td>28025</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>ENERGY_COMPANY</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://instagram.fsaw2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     username          id                    full_name  \\\n",
              "0              beyazyakaliyiz  8634457436           Selam Beyaz Yakalı   \n",
              "1  totalenergies_istasyonlari  7066643793  TotalEnergies İstasyonları   \n",
              "\n",
              "                                           biography   category_name  \\\n",
              "0        Beyaz yakalıların dünyasına hoşgeldiniz 😀😀😀   Personal blog   \n",
              "1  TotalEnergies İstasyonları resmi Instagram hes...  Energy Company   \n",
              "\n",
              "  post_count follower_count following_count is_business_account is_private  \\\n",
              "0       None           1265             665                True      False   \n",
              "1       None          28025               4                True      False   \n",
              "\n",
              "   ... business_category_name overall_category_name   category_enum  \\\n",
              "0  ...                   None                  None   PERSONAL_BLOG   \n",
              "1  ...                   None                  None  ENERGY_COMPANY   \n",
              "\n",
              "  is_verified_by_mv4b is_regulated_c18  \\\n",
              "0               False            False   \n",
              "1               False            False   \n",
              "\n",
              "                                     profile_pic_url should_show_category  \\\n",
              "0  https://instagram.fist6-1.fna.fbcdn.net/v/t51....                 True   \n",
              "1  https://instagram.fsaw2-1.fna.fbcdn.net/v/t51....                 True   \n",
              "\n",
              "  should_show_public_contacts show_account_transparency_details  \\\n",
              "0                        True                              True   \n",
              "1                        True                              True   \n",
              "\n",
              "                              profile_picture_base64  \n",
              "0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
              "1  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
              "\n",
              "[2 rows x 44 columns]"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test Profie Dataframe\n",
        "test_profile_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Z5UY0eYLsoTr"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Improved preprocessing function\n",
        "def preprocess_text(text: str):\n",
        "    text = text.casefold()\n",
        "    \n",
        "    # Enhanced emoji handling\n",
        "    text = emoji.demojize(text) # Convert emojis to text\n",
        "    \n",
        "    # Better URL handling\n",
        "    text = re.sub(r'http[s]?://\\S+|www\\.\\S+', 'URL', text)\n",
        "    \n",
        "    # Enhanced hashtag handling - preserve important terms\n",
        "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
        "    \n",
        "    # Improved mention handling\n",
        "    text = re.sub(r'@(\\w+)', 'USER', text)\n",
        "    \n",
        "    # Handle numbers more intelligently\n",
        "    text = re.sub(r'\\d+k\\b', 'THOUSAND', text) # Handle 1k, 2k etc.\n",
        "    text = re.sub(r'\\d+m\\b', 'MILLION', text)\n",
        "    text = re.sub(r'\\d+(\\.\\d+)?', 'NUMBER', text)\n",
        "    \n",
        "    # Keep important punctuation\n",
        "    text = re.sub(r'[^\\w\\s!?.]', ' ', text)\n",
        "    \n",
        "    # Handle multiple spaces\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text\n",
        "\n",
        "def extract_additional_features(profile, posts):\n",
        "    features = {}\n",
        "    \n",
        "    # Profile-based features\n",
        "    follower_count = profile.get('follower_count', 0) or 0\n",
        "    following_count = profile.get('following_count', 0) or 0\n",
        "    features['follower_engagement_ratio'] = follower_count / (following_count + 1)\n",
        "    features['is_verified'] = int(profile.get('is_verified', False))\n",
        "    features['has_external_url'] = 1 if profile.get('external_url') else 0\n",
        "    \n",
        "    # Post-based features\n",
        "    post_likes = [p.get('like_count', 0) or 0 for p in posts]\n",
        "    features['avg_likes'] = np.mean(post_likes) if post_likes else 0\n",
        "    features['like_variance'] = np.var(post_likes) if post_likes else 0\n",
        "    features['engagement_rate'] = features['avg_likes'] / (follower_count + 1)\n",
        "    \n",
        "    return features\n",
        "\n",
        "# Initialize corpus and train usernames\n",
        "corpus = []\n",
        "train_usernames = []\n",
        "\n",
        "# Preprocess training data\n",
        "for username, posts in username2posts_train.items():\n",
        "    train_usernames.append(username)\n",
        "    \n",
        "    cleaned_captions = []\n",
        "    for post in posts:\n",
        "        post_caption = post.get(\"caption\", \"\")\n",
        "        if post_caption is None:\n",
        "            continue\n",
        "        \n",
        "        post_caption = preprocess_text(post_caption)\n",
        "        \n",
        "        if post_caption != \"\":\n",
        "            cleaned_captions.append(post_caption)\n",
        "    \n",
        "    # Joining the posts of each user with a separator (helps retain user-specific context)\n",
        "    user_post_captions = \" <SEP> \".join(cleaned_captions)\n",
        "    corpus.append(user_post_captions)\n",
        "\n",
        "# Update TF-IDF parameters for improved feature extraction\n",
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words=turkish_stopwords,\n",
        "    max_features=10000,         # Increased feature count for richer representation\n",
        "    ngram_range=(1, 2),         # Use unigrams and bigrams\n",
        "    sublinear_tf=True,          # Use logarithmic scaling for term frequency\n",
        "    max_df=0.7,                 # Ignore terms appearing in >70% of documents\n",
        "    min_df=3                    # Ignore terms appearing in <3 documents\n",
        ")\n",
        "\n",
        "# Fit the vectorizer\n",
        "vectorizer.fit(corpus)\n",
        "\n",
        "# Transform training data\n",
        "x_post_train = vectorizer.transform(corpus)\n",
        "\n",
        "# Assign labels to training data\n",
        "y_train = [username2_category.get(uname, \"NA\") for uname in train_usernames]\n",
        "\n",
        "# Preprocess test data\n",
        "test_usernames = []\n",
        "test_corpus = []\n",
        "\n",
        "for username, posts in username2posts_test.items():\n",
        "    test_usernames.append(username)\n",
        "    \n",
        "    cleaned_captions = []\n",
        "    for post in posts:\n",
        "        post_caption = post.get(\"caption\", \"\")\n",
        "        if post_caption is None:\n",
        "            continue\n",
        "        \n",
        "        post_caption = preprocess_text(post_caption)\n",
        "        \n",
        "        if post_caption != \"\":\n",
        "            cleaned_captions.append(post_caption)\n",
        "    \n",
        "    user_post_captions = \" <SEP> \".join(cleaned_captions)\n",
        "    test_corpus.append(user_post_captions)\n",
        "\n",
        "# Transform test data (do not fit again!)\n",
        "x_post_test = vectorizer.transform(test_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "Q-BcPjw_39aP"
      },
      "outputs": [],
      "source": [
        "# Making sure everything is fine\n",
        "assert y_train.count(\"NA\") == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP9ZrOIAvi9z",
        "outputId": "47634b8e-f5d0-4160-aab4-2cc60b4900e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['_________________________', 'abd', 'abdullah', ..., 'جملة', 'على',\n",
              "       'في'], dtype=object)"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "xa4v453o0Mo_",
        "outputId": "4787ecd7-ba6f-44aa-fa0a-cdaf39d33d3a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_________________________</th>\n",
              "      <th>abd</th>\n",
              "      <th>abdullah</th>\n",
              "      <th>abi</th>\n",
              "      <th>abiye</th>\n",
              "      <th>abone</th>\n",
              "      <th>about</th>\n",
              "      <th>about the</th>\n",
              "      <th>abs</th>\n",
              "      <th>ac</th>\n",
              "      <th>...</th>\n",
              "      <th>şıklık</th>\n",
              "      <th>şıklığı</th>\n",
              "      <th>на</th>\n",
              "      <th>по</th>\n",
              "      <th>اسطنبول</th>\n",
              "      <th>به</th>\n",
              "      <th>تركيا</th>\n",
              "      <th>جملة</th>\n",
              "      <th>على</th>\n",
              "      <th>في</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 10000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   _________________________  abd  abdullah  abi  abiye  abone  about  \\\n",
              "0                        0.0  0.0       0.0  0.0    0.0    0.0    0.0   \n",
              "1                        0.0  0.0       0.0  0.0    0.0    0.0    0.0   \n",
              "\n",
              "   about the  abs   ac  ...  şıklık  şıklığı   на   по  اسطنبول   به  تركيا  \\\n",
              "0        0.0  0.0  0.0  ...     0.0      0.0  0.0  0.0      0.0  0.0    0.0   \n",
              "1        0.0  0.0  0.0  ...     0.0      0.0  0.0  0.0      0.0  0.0    0.0   \n",
              "\n",
              "   جملة  على   في  \n",
              "0   0.0  0.0  0.0  \n",
              "1   0.0  0.0  0.0  \n",
              "\n",
              "[2 rows x 10000 columns]"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tfidf = pd.DataFrame(x_post_train.toarray(), columns=feature_names)\n",
        "df_tfidf.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i9xO_ZX1NXC",
        "outputId": "15c76222-630d-4c3c-9ba5-96a44af78a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2741, 10000)\n"
          ]
        }
      ],
      "source": [
        "print(df_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "ehUT3JSFz7yo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(df_tfidf, y_train, test_size=0.2, stratify=y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipJX5GBZ1efb",
        "outputId": "dde21a01-9349-44de-cc16-3605f332f756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2192, 10000)\n",
            "(549, 10000)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "\n",
        "print(x_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'C': 10, 'class_weight': 'balanced', 'solver': 'liblinear'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1.0, 10],\n",
        "    'solver': ['liblinear', 'lbfgs'],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "# Grid search for Logistic Regression\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(max_iter=500),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best parameters:\", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khu0eryhNZNN"
      },
      "source": [
        "# Naive Base Classifier\n",
        "\n",
        "### Now we can pass the numerical values to a classifier, Let's try Naive Base!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "rdHIvFrSCMZj",
        "outputId": "043e1aaf-0e8b-4b20-8a32-c27298d253ac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=500,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=500,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=10, class_weight='balanced', max_iter=500,\n",
              "                   solver='liblinear')"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train a Logistic Regression model with balanced class weights\n",
        "model = LogisticRegression(\n",
        "    class_weight='balanced', \n",
        "    max_iter=500, \n",
        "    solver='liblinear', \n",
        "    penalty='l2', \n",
        "    C=10\n",
        ")\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyY9aFtGDrAj",
        "outputId": "e44c466d-6bf0-4556-ad4b-7c7111ad2835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9908759124087592\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "                 art       0.99      0.99      0.99       153\n",
            "       entertainment       1.00      0.99      0.99       258\n",
            "             fashion       0.99      0.99      0.99       239\n",
            "                food       0.98      1.00      0.99       409\n",
            "              gaming       1.00      1.00      1.00        10\n",
            "health and lifestyle       1.00      0.98      0.99       402\n",
            "    mom and children       0.99      1.00      1.00       119\n",
            "              sports       1.00      1.00      1.00        90\n",
            "                tech       0.99      1.00      0.99       277\n",
            "              travel       0.99      0.99      0.99       235\n",
            "\n",
            "            accuracy                           0.99      2192\n",
            "           macro avg       0.99      0.99      0.99      2192\n",
            "        weighted avg       0.99      0.99      0.99      2192\n",
            "\n",
            "Accuracy: 0.6903460837887068\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "                 art       0.46      0.32      0.37        38\n",
            "       entertainment       0.47      0.54      0.50        65\n",
            "             fashion       0.69      0.78      0.73        60\n",
            "                food       0.93      0.89      0.91       102\n",
            "              gaming       0.00      0.00      0.00         3\n",
            "health and lifestyle       0.62      0.73      0.67       100\n",
            "    mom and children       0.88      0.50      0.64        30\n",
            "              sports       0.84      0.70      0.76        23\n",
            "                tech       0.70      0.75      0.73        69\n",
            "              travel       0.70      0.64      0.67        59\n",
            "\n",
            "            accuracy                           0.69       549\n",
            "           macro avg       0.63      0.59      0.60       549\n",
            "        weighted avg       0.70      0.69      0.69       549\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Validation Data\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_train_pred = model.predict(x_train)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, zero_division=0))\n",
        "\n",
        "\n",
        "y_val_pred = model.predict(x_val)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_val_pred, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU6aALFaCMkd",
        "outputId": "83913a4f-45bc-4e1a-e069-06d452f31255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ozhotelstr\n",
            "elleturkiye\n",
            "sozerinsaatorhangazi\n",
            "sanliurfapiazzaavym\n",
            "rusanozden\n",
            "*****\n",
            "['ozhotelstr', 'elleturkiye', 'sozerinsaatorhangazi', 'sanliurfapiazzaavym', 'rusanozden']\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the testing directory\n",
        "testing_dir = os.path.join(data_dir, 'testing')\n",
        "\n",
        "# File path for 'test-classification-round1.dat'\n",
        "test_data_path = os.path.join(testing_dir, 'test-classification-round1.dat')\n",
        "\n",
        "# Step 2: Preview First 5 Lines of the Test File\n",
        "with open(test_data_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for i, line in enumerate(fh):\n",
        "        print(line.strip())\n",
        "        if i == 4:  # Print only the first 5 lines\n",
        "            break\n",
        "\n",
        "print(\"*****\")\n",
        "\n",
        "# Step 3: Extract Usernames from Test Data\n",
        "test_unames = []\n",
        "with open(test_data_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for line in fh:\n",
        "        test_unames.append(line.strip())\n",
        "\n",
        "# Step 4: Verify Output\n",
        "print(test_unames[:5])  # Display the first 5 usernames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqLF4LN8GqKm",
        "outputId": "779e32d6-a7be-4a03-d6c9-7f601b68cdbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "screenname\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_________________________</th>\n",
              "      <th>abd</th>\n",
              "      <th>abdullah</th>\n",
              "      <th>abi</th>\n",
              "      <th>abiye</th>\n",
              "      <th>abone</th>\n",
              "      <th>about</th>\n",
              "      <th>about the</th>\n",
              "      <th>abs</th>\n",
              "      <th>ac</th>\n",
              "      <th>...</th>\n",
              "      <th>şıklık</th>\n",
              "      <th>şıklığı</th>\n",
              "      <th>на</th>\n",
              "      <th>по</th>\n",
              "      <th>اسطنبول</th>\n",
              "      <th>به</th>\n",
              "      <th>تركيا</th>\n",
              "      <th>جملة</th>\n",
              "      <th>على</th>\n",
              "      <th>في</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.02918</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 10000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   _________________________      abd  abdullah  abi  abiye  abone  about  \\\n",
              "0                        0.0  0.00000       0.0  0.0    0.0    0.0    0.0   \n",
              "1                        0.0  0.02918       0.0  0.0    0.0    0.0    0.0   \n",
              "\n",
              "   about the  abs   ac  ...  şıklık  şıklığı   на   по  اسطنبول   به  تركيا  \\\n",
              "0        0.0  0.0  0.0  ...     0.0      0.0  0.0  0.0      0.0  0.0    0.0   \n",
              "1        0.0  0.0  0.0  ...     0.0      0.0  0.0  0.0      0.0  0.0    0.0   \n",
              "\n",
              "   جملة  على   في  \n",
              "0   0.0  0.0  0.0  \n",
              "1   0.0  0.0  0.0  \n",
              "\n",
              "[2 rows x 10000 columns]"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test = []\n",
        "\n",
        "for uname in test_unames:\n",
        "  try:\n",
        "    index = test_usernames.index(uname)\n",
        "    x_test.append(x_post_test[index].toarray()[0])\n",
        "  except Exception as e:\n",
        "    try:\n",
        "      index = train_usernames.index(uname)\n",
        "      x_test.append(x_post_train[index].toarray()[0])\n",
        "    except Exception as e:\n",
        "      print(uname)\n",
        "\n",
        "\n",
        "print(test_unames.remove(\"screenname\"))\n",
        "\n",
        "df_test = pd.DataFrame(np.array(x_test), columns=feature_names)\n",
        "df_test.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "gUsUQtpMKTse"
      },
      "outputs": [],
      "source": [
        "test_pred = model.predict(df_test)\n",
        "\n",
        "output = dict()\n",
        "for index, uname in enumerate(test_unames):\n",
        "  output[uname] = test_pred[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "W-NJSnyxIrw4"
      },
      "outputs": [],
      "source": [
        "with open(\"output.json\", \"w\") as of:\n",
        "  json.dump(output, of, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC7KXsQZL7Kp"
      },
      "source": [
        "# Like Count Prediction\n",
        "\n",
        "\n",
        "Here, we use the average like_count of the user's previous posts to predict each post's like_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "nolpagasSuBq"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "def extract_post_features(post):\n",
        "    \"\"\"Extract comprehensive features from a post\"\"\"\n",
        "    timestamp = pd.to_datetime(post.get('timestamp', None))\n",
        "    caption = post.get('caption', '')\n",
        "    \n",
        "    features = {\n",
        "        # Temporal features\n",
        "        'hour': timestamp.hour if timestamp else 0,\n",
        "        'day_of_week': timestamp.dayofweek if timestamp else 0,\n",
        "        'is_weekend': int(timestamp.dayofweek >= 5) if timestamp else 0,\n",
        "        \n",
        "        # Content features\n",
        "        'caption_length': len(caption) if caption else 0,\n",
        "        'has_caption': int(bool(caption)),\n",
        "        'emoji_count': sum(1 for c in caption if c in emoji.EMOJI_DATA) if caption else 0,\n",
        "        'hashtag_count': caption.count('#') if caption else 0,\n",
        "        'mention_count': caption.count('@') if caption else 0,\n",
        "        \n",
        "        # Engagement features\n",
        "        'comments_count': post.get('comments_count', 0) or 0,\n",
        "        'is_video': int(post.get('media_type', '') == 'VIDEO'),\n",
        "        'is_carousel': int(post.get('media_type', '') == 'CAROUSEL_ALBUM'),\n",
        "    }\n",
        "    \n",
        "    return features\n",
        "\n",
        "def extract_profile_features(profile):\n",
        "    \"\"\"Extract comprehensive features from a profile\"\"\"\n",
        "    bio = profile.get('biography', '')\n",
        "    \n",
        "    return {\n",
        "        'follower_count': profile.get('follower_count', 0) or 0,\n",
        "        'following_count': profile.get('following_count', 0) or 0,\n",
        "        'post_count': profile.get('post_count', 0) or 0,\n",
        "        'is_verified': int(profile.get('is_verified', False)),\n",
        "        'is_business': int(profile.get('is_business_account', False)),\n",
        "        'bio_length': len(bio) if bio else 0,\n",
        "        'has_external_url': int(bool(profile.get('external_url', ''))),\n",
        "        'engagement_ratio': (profile.get('follower_count', 0) or 0) / \n",
        "                          (profile.get('following_count', 1) or 1)\n",
        "    }\n",
        "\n",
        "def predict_like_count(username, current_post=None):\n",
        "    \"\"\"Predict like count using advanced regression model\"\"\"\n",
        "    posts = username2posts_train.get(username) or username2posts_test.get(username)\n",
        "    profile = username2profile_train.get(username) or username2profile_test.get(username)\n",
        "    \n",
        "    if not posts or not profile:\n",
        "        return 0\n",
        "        \n",
        "    # Prepare training data\n",
        "    X = []\n",
        "    y = []\n",
        "    \n",
        "    for post in posts:\n",
        "        if current_post and post['id'] == current_post['id']:\n",
        "            continue\n",
        "            \n",
        "        post_features = extract_post_features(post)\n",
        "        profile_features = extract_profile_features(profile)\n",
        "        \n",
        "        # Combine features\n",
        "        features = {**post_features, **profile_features}\n",
        "        X.append(features)\n",
        "        y.append(post.get('like_count', 0) or 0)\n",
        "    \n",
        "    if not X:\n",
        "        return 0\n",
        "    \n",
        "    # Convert to DataFrame and handle missing values\n",
        "    X_df = pd.DataFrame(X)\n",
        "    X_df = X_df.fillna(0)\n",
        "    \n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_df)\n",
        "    \n",
        "    # Transform target variable (log transformation for better handling of skewed data)\n",
        "    y = np.log1p(y)\n",
        "    \n",
        "    # Train model with optimized parameters\n",
        "    model = XGBRegressor(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        min_child_weight=3,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=1,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    model.fit(X_scaled, y)\n",
        "    \n",
        "    # Predict for current post\n",
        "    if current_post:\n",
        "        features = {**extract_post_features(current_post), **extract_profile_features(profile)}\n",
        "        X_pred = pd.DataFrame([features])\n",
        "        X_pred = X_pred.fillna(0)\n",
        "        X_pred_scaled = scaler.transform(X_pred)\n",
        "        \n",
        "        # Transform prediction back to original scale\n",
        "        prediction = np.expm1(model.predict(X_pred_scaled)[0])\n",
        "        return int(max(0, prediction))\n",
        "    \n",
        "    # Return mean if no current post (for initialization)\n",
        "    return int(np.mean(np.expm1(y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "ZNWTjLZ6XAuj"
      },
      "outputs": [],
      "source": [
        "def log_mse_like_counts(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculate the Log Mean Squared Error (Log MSE) for like counts (log(like_count + 1)).\n",
        "\n",
        "  Parameters:\n",
        "  - y_true: array-like, actual like counts\n",
        "  - y_pred: array-like, predicted like counts\n",
        "\n",
        "  Returns:\n",
        "  - log_mse: float, Log Mean Squared Error\n",
        "  \"\"\"\n",
        "  # Ensure inputs are numpy arrays\n",
        "  y_true = np.array(y_true)\n",
        "  y_pred = np.array(y_pred)\n",
        "\n",
        "  # Log transformation: log(like_count + 1)\n",
        "  log_y_true = np.log1p(y_true)\n",
        "  log_y_pred = np.log1p(y_pred)\n",
        "\n",
        "  # Compute squared errors\n",
        "  squared_errors = (log_y_true - log_y_pred) ** 2\n",
        "\n",
        "  # Return the mean of squared errors\n",
        "  return np.mean(squared_errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1jETdAuXA0H",
        "outputId": "871164d0-74fb-49cd-ea77-b8a3e0793e81"
      },
      "outputs": [],
      "source": [
        "# Train Dataset evaluation\n",
        "\n",
        "y_like_count_train_true = []\n",
        "y_like_count_train_pred = []\n",
        "for uname, posts in username2posts_train.items():\n",
        "  for post in posts:\n",
        "    pred_val = predict_like_count(uname, post)\n",
        "    true_val = post.get(\"like_count\", 0)\n",
        "    if true_val is None:\n",
        "      true_val = 0\n",
        "\n",
        "    y_like_count_train_true.append(true_val)\n",
        "    y_like_count_train_pred.append(pred_val)\n",
        "\n",
        "print(f\"Log MSE Train= {log_mse_like_counts(y_like_count_train_true, y_like_count_train_pred)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "F02V1wO-WBMV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed data saved to: c:\\Users\\itsmm\\OneDrive\\Desktop\\CS412\\CS412-InstagramInfluencersAnalysis\\data\\output\\test-regression-round1.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the testing directory\n",
        "testing_dir = os.path.join(data_dir, 'testing')\n",
        "\n",
        "# File path for 'test-regression-round1.jsonl'\n",
        "test_dataset_path = os.path.join(testing_dir, 'test-regression-round1.jsonl')\n",
        "\n",
        "# File path for output\n",
        "output_dir = os.path.join(data_dir, 'output')\n",
        "os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
        "output_file_path = os.path.join(output_dir, 'test-regression-round1.jsonl')\n",
        "\n",
        "# Step 2: Process the Test Dataset\n",
        "to_predict_like_counts_usernames = []\n",
        "output_list = []\n",
        "\n",
        "with open(test_dataset_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for line in fh:\n",
        "        sample = json.loads(line)\n",
        "\n",
        "        # Perform prediction\n",
        "        pred_val = predict_like_count(sample[\"username\"])  # Ensure `predict_like_count` is defined\n",
        "        sample[\"like_count\"] = int(pred_val)\n",
        "        output_list.append(sample)\n",
        "\n",
        "# Step 3: Save the Output to a File\n",
        "with open(output_file_path, \"wt\", encoding=\"utf-8\") as of:\n",
        "    json.dump(output_list, of)\n",
        "\n",
        "# Step 4: Output Verification\n",
        "print(f\"Processed data saved to: {output_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blI2SqvvvOF8",
        "outputId": "fe1e72e3-3ad0-486d-d054-3e90e8c66669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'caption': 'KOZA 2023 2.si Damla’nın koleksiyonu, Latincede ‘Memento Mori’ '\n",
            "             'olarak bilinen ‘ölümlü olduğunu hatırla’ anlamındaki ifadeden '\n",
            "             'esinleniyor. Koleksiyon, hayatın ve ölümün, para, işçi, kral ve '\n",
            "             'kraliçe kavramları üzerinden yaratıcı görünümlerle bir araya '\n",
            "             'getirilmesini amaçlıyor. Ölüm sembollerinden esinlenen desenler '\n",
            "             'kullanan Damla, “kağıt parçasından ibaret olmak” kavramını '\n",
            "             'vurguluyor. Koleksiyon, yaşamın ve ölümün aynı anda ifade '\n",
            "             'edilmesini hedefliyor; kırmızı ve mavi ışıklarla veya '\n",
            "             'gözlüklerle görülen hologram efekti kullanılarak bu konsept '\n",
            "             'sahneye taşınıyor. Kırmızı renk ölümü, mavi ise yaşamı '\n",
            "             'simgeliyor. Koleksiyon, ofis giyimlerinden esinlenerek '\n",
            "             'kravatlar, gömlekler ve evrak çantaları içeriyor. Klasik sivri '\n",
            "             'burun çizmelerin üzerine spor ayakkabıların üst yüzeyi '\n",
            "             'yerleştirilerek, iş dünyasının koşuşturması ve cenaze '\n",
            "             'temalarının aynı anda ifade edilmesi amaçlanıyor. Para kazanma '\n",
            "             'arzusu, kırmızı zambak desenleri ve büyük mücevher görünümleri '\n",
            "             'ile koleksiyon tamamlanıyor.\\n'\n",
            "             '\\n'\n",
            "             'Tebrikler Damla!\\n'\n",
            "             '\\n'\n",
            "             '#GencModaTasarimcilari #Koza2023 #KozaYarismasi '\n",
            "             '#TasarimYarismasi #Moda #Fashion #ModaTasarımı',\n",
            "  'comments_count': 2,\n",
            "  'id': '18144550534306740',\n",
            "  'like_count': 158,\n",
            "  'media_type': 'CAROUSEL_ALBUM',\n",
            "  'media_url': 'https://scontent-sof1-1.cdninstagram.com/v/t51.29350-15/397997154_1016992459537522_4925783512176260397_n.jpg?_nc_cat=106&ccb=1-7&_nc_sid=c4dd86&_nc_ohc=7V_eObkFeK4AX-LMtsK&_nc_ht=scontent-sof1-1.cdninstagram.com&edm=AL-3X8kEAAAA&oh=00_AfDEqDhzaTO3ezV-veT6cJFCOcAEyeVzHR6si9n33N6G5A&oe=6551B6B9',\n",
            "  'timestamp': '2023-11-02 15:49:22',\n",
            "  'username': 'kozayarismasi'},\n",
            " {'caption': 'Tüm Türkiye ve Avrupa’ya sevkiyatlarımız aralıksız devam ediyor! '\n",
            "             'Aracımız Bursa’dan Ordu’ya müşterimizin ürünleri için yola '\n",
            "             'çıkıyor.\\n'\n",
            "             '\\n'\n",
            "             '👉Tuna Mah. Etibank Cad. No:134 Osmangazi/BURSA\\n'\n",
            "             '\\n'\n",
            "             'www.celikbeymobilya.com sitemizden tüm modelleri '\n",
            "             'inceleyebilirsiniz. \\n'\n",
            "             '\\n'\n",
            "             '#bursa #almanya #fransa',\n",
            "  'comments_count': 0,\n",
            "  'id': '17995331788956693',\n",
            "  'like_count': 99,\n",
            "  'media_type': 'VIDEO',\n",
            "  'media_url': 'https://scontent-sof1-2.cdninstagram.com/o1/v/t16/f1/m82/BF4767CB85BDFB8ADCCCA8F15B8C20B5_video_dashinit.mp4?efg=eyJ2ZW5jb2RlX3RhZyI6InZ0c192b2RfdXJsZ2VuLmNsaXBzLnVua25vd24tQzMuNzIwLmRhc2hfYmFzZWxpbmVfMV92MSJ9&_nc_ht=scontent-sof1-2.cdninstagram.com&_nc_cat=110&vs=1259525061418244_1441854817&_nc_vs=HBksFQIYT2lnX3hwdl9yZWVsc19wZXJtYW5lbnRfcHJvZC9CRjQ3NjdDQjg1QkRGQjhBRENDQ0E4RjE1QjhDMjBCNV92aWRlb19kYXNoaW5pdC5tcDQVAALIAQAVAhg6cGFzc3Rocm91Z2hfZXZlcnN0b3JlL0dBRWdfaFZfcDVCYk5HZ0NBQTlzVURvZW5mZ3FicV9FQUFBRhUCAsgBACgAGAAbAYgHdXNlX29pbAExFQAAJvS3uOiQ0P8%2FFQIoAkMzLBdAJO%2Bdsi0OVhgSZGFzaF9iYXNlbGluZV8xX3YxEQB1AAA%3D&ccb=9-4&oh=00_AfAm22JssMPaUlQe3rpYsFWBhFb5mUgolTCdhV0Xgm4AnA&oe=6556A482&_nc_sid=1d576d&_nc_rid=cd9a998e44',\n",
            "  'timestamp': '2023-08-19 13:46:02',\n",
            "  'username': 'celikbeymobilya'},\n",
            " {'caption': '🤩\\n'\n",
            "             '\\n'\n",
            "             '.\\n'\n",
            "             '.\\n'\n",
            "             'Daha Fazlası İçin Beğenmeyi ve Takip Etmeyi Unutmayın\\n'\n",
            "             '.\\n'\n",
            "             'girisimci_muhendis ✅\\n'\n",
            "             '.\\n'\n",
            "             '📣Bu Bilgi Hakkında Ne Düşünüyorsunuz.\\n'\n",
            "             '.\\n'\n",
            "             '✅Görmesini İstediğin Arkadaşını Etiketle.\\n'\n",
            "             '.\\n'\n",
            "             '🔔Gönderi Bildirimlerini Açarak, Bilgileri Anında '\n",
            "             'Öğrenebilirsiniz.\\n'\n",
            "             '\\n'\n",
            "             '.\\n'\n",
            "             '\\n'\n",
            "             'Source: Unknown\\n'\n",
            "             'Dm for Credit or removal\\n'\n",
            "             '.\\n'\n",
            "             '.............................................................\\n'\n",
            "             'All rights and credits reserved to the respective owner(s). If '\n",
            "             'you are the main copyright owner rather than the one mentioned '\n",
            "             'here of this content, contact me to claim credit or content '\n",
            "             'removal',\n",
            "  'comments_count': 75,\n",
            "  'id': '18302703232191518',\n",
            "  'like_count': 1224,\n",
            "  'media_type': 'VIDEO',\n",
            "  'media_url': None,\n",
            "  'timestamp': '2023-10-02 06:53:33',\n",
            "  'username': 'girisimci_muhendis'}]\n"
          ]
        }
      ],
      "source": [
        "# output_list first 3 items\n",
        "pprint(output_list[:3])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
