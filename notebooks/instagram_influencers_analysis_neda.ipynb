{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBOlFYpnlr0N"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "PM5EnXhLk6BL"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\itsmm\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "import os\n",
        "import gzip\n",
        "import json\n",
        "from pprint import pprint\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Turkish StopWords\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "turkish_stopwords = stopwords.words('turkish')\n",
        "\n",
        "import emoji\n",
        "from xgboost import XGBClassifier, XGBRegressor\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plt9-VkNmlmH"
      },
      "source": [
        "# Influencer Category Classification\n",
        "\n",
        "\n",
        "\n",
        "1.   Read Data\n",
        "2.   Preprocess Data\n",
        "3.   Prepare Model\n",
        "4.   Predict Test Data\n",
        "4.   Save outputs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "8DeBh-b7lrEs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First few rows of the training classification DataFrame:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>taskirancemal</td>\n",
              "      <td>mom and children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tam_kararinda</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spart4nn</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sosyalyiyiciler</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sonaydizdarahad</td>\n",
              "      <td>mom and children</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           user_id          category\n",
              "0    taskirancemal  mom and children\n",
              "1    tam_kararinda              food\n",
              "2         spart4nn              food\n",
              "3  sosyalyiyiciler              food\n",
              "4  sonaydizdarahad  mom and children"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the training directory\n",
        "training_dir = os.path.join(data_dir, 'training')\n",
        "\n",
        "# File path for 'train-classification.csv'\n",
        "train_classification_path = os.path.join(training_dir, 'train-classification.csv')\n",
        "\n",
        "# Step 2: Load Data Dynamically\n",
        "train_classification_df = pd.read_csv(train_classification_path)\n",
        "train_classification_df = train_classification_df.rename(columns={'Unnamed: 0': 'user_id', 'label': 'category'})\n",
        "\n",
        "# Step 3: Unify Labels\n",
        "train_classification_df[\"category\"] = train_classification_df[\"category\"].apply(str.lower)\n",
        "\n",
        "# Step 4: Create User-to-Category Mapping\n",
        "username2_category = train_classification_df.set_index(\"user_id\").to_dict()[\"category\"]\n",
        "\n",
        "# Step 5: Verify Output\n",
        "print(\"First few rows of the training classification DataFrame:\")\n",
        "train_classification_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "SfD7BQ3hE5Jh",
        "outputId": "a67f08dd-ab3e-491f-bfe2-a14da0e961cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tech\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>art</th>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>entertainment</th>\n",
              "      <td>323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fashion</th>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>food</th>\n",
              "      <td>511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gaming</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>health and lifestyle</th>\n",
              "      <td>503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mom and children</th>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sports</th>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tech</th>\n",
              "      <td>346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>travel</th>\n",
              "      <td>294</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      user_id\n",
              "category                     \n",
              "art                       191\n",
              "entertainment             323\n",
              "fashion                   299\n",
              "food                      511\n",
              "gaming                     13\n",
              "health and lifestyle      503\n",
              "mom and children          149\n",
              "sports                    113\n",
              "tech                      346\n",
              "travel                    294"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(username2_category[\"kod8net\"] + \"\\n\")\n",
        "\n",
        "# stats about the labels\n",
        "train_classification_df.groupby(\"category\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "GT_IcUM2nGBH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Training Users: 2741\n",
            "Number of Testing Users: 2674\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the training directory\n",
        "training_dir = os.path.join(data_dir, 'training')\n",
        "\n",
        "# File path for 'training-dataset.jsonl.gz'\n",
        "train_data_path = os.path.join(training_dir, 'training-dataset.jsonl.gz')\n",
        "\n",
        "# Step 2: Initialize Dictionaries for Data\n",
        "username2posts_train = dict()\n",
        "username2profile_train = dict()\n",
        "\n",
        "username2posts_test = dict()\n",
        "username2profile_test = dict()\n",
        "\n",
        "# Step 3: Process Data from 'training-dataset.jsonl.gz'\n",
        "with gzip.open(train_data_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for line in fh:\n",
        "        sample = json.loads(line)\n",
        "\n",
        "        profile = sample[\"profile\"]\n",
        "        username = profile.get(\"username\", \"\").strip()  # Handle missing or empty usernames\n",
        "        if not username:\n",
        "            continue  # Skip if username is missing or empty\n",
        "\n",
        "        if username in username2_category:\n",
        "            # Train data info\n",
        "            username2posts_train[username] = sample[\"posts\"]\n",
        "            username2profile_train[username] = profile\n",
        "        else:\n",
        "            # Test data info\n",
        "            username2posts_test[username] = sample[\"posts\"]\n",
        "            username2profile_test[username] = profile\n",
        "\n",
        "# Step 4: Verify Output\n",
        "print(f\"Number of Training Users: {len(username2posts_train)}\")\n",
        "print(f\"Number of Testing Users: {len(username2posts_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "djeF1GQ1oy3v",
        "outputId": "5c2ead24-d7d1-4df8-bec0-bf2152c76832"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>id</th>\n",
              "      <th>full_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>category_name</th>\n",
              "      <th>post_count</th>\n",
              "      <th>follower_count</th>\n",
              "      <th>following_count</th>\n",
              "      <th>is_business_account</th>\n",
              "      <th>is_private</th>\n",
              "      <th>...</th>\n",
              "      <th>business_category_name</th>\n",
              "      <th>overall_category_name</th>\n",
              "      <th>category_enum</th>\n",
              "      <th>is_verified_by_mv4b</th>\n",
              "      <th>is_regulated_c18</th>\n",
              "      <th>profile_pic_url</th>\n",
              "      <th>should_show_category</th>\n",
              "      <th>should_show_public_contacts</th>\n",
              "      <th>show_account_transparency_details</th>\n",
              "      <th>profile_picture_base64</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>deparmedya</td>\n",
              "      <td>3170700063</td>\n",
              "      <td>Depar Medya</td>\n",
              "      <td>#mediaplanning #mediabuying #sosyalmedya</td>\n",
              "      <td>Local business</td>\n",
              "      <td>None</td>\n",
              "      <td>1167</td>\n",
              "      <td>192</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>LOCAL</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://instagram.fsaw2-3.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kafesfirin</td>\n",
              "      <td>266439571</td>\n",
              "      <td>KAFES FIRIN</td>\n",
              "      <td>üìçSoÃàgÃÜuÃàtoÃàzuÃàüìçFTZ AVM\\nüõíAnkara macro‚ñ≤center v...</td>\n",
              "      <td>Brand</td>\n",
              "      <td>None</td>\n",
              "      <td>11997</td>\n",
              "      <td>17</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>BRAND</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://instagram.fada1-13.fna.fbcdn.net/v/t51...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows √ó 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     username          id    full_name  \\\n",
              "0  deparmedya  3170700063  Depar Medya   \n",
              "1  kafesfirin   266439571  KAFES FIRIN   \n",
              "\n",
              "                                           biography   category_name  \\\n",
              "0           #mediaplanning #mediabuying #sosyalmedya  Local business   \n",
              "1  üìçSoÃàgÃÜuÃàtoÃàzuÃàüìçFTZ AVM\\nüõíAnkara macro‚ñ≤center v...           Brand   \n",
              "\n",
              "  post_count follower_count following_count is_business_account is_private  \\\n",
              "0       None           1167             192                True      False   \n",
              "1       None          11997              17                True      False   \n",
              "\n",
              "   ... business_category_name overall_category_name category_enum  \\\n",
              "0  ...                   None                  None         LOCAL   \n",
              "1  ...                   None                  None         BRAND   \n",
              "\n",
              "  is_verified_by_mv4b is_regulated_c18  \\\n",
              "0               False            False   \n",
              "1               False            False   \n",
              "\n",
              "                                     profile_pic_url should_show_category  \\\n",
              "0  https://instagram.fsaw2-3.fna.fbcdn.net/v/t51....                 True   \n",
              "1  https://instagram.fada1-13.fna.fbcdn.net/v/t51...                 True   \n",
              "\n",
              "  should_show_public_contacts show_account_transparency_details  \\\n",
              "0                        True                              True   \n",
              "1                        True                              True   \n",
              "\n",
              "                              profile_picture_base64  \n",
              "0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
              "1  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
              "\n",
              "[2 rows x 44 columns]"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Profile Dataframe\n",
        "train_profile_df = pd.DataFrame(username2profile_train).T.reset_index(drop=True)\n",
        "test_profile_df = pd.DataFrame(username2profile_test).T.reset_index(drop=True)\n",
        "\n",
        "train_profile_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "15tvVohUBHK9",
        "outputId": "15be2533-51b2-41e8-e0f2-26a44933dbae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>id</th>\n",
              "      <th>full_name</th>\n",
              "      <th>biography</th>\n",
              "      <th>category_name</th>\n",
              "      <th>post_count</th>\n",
              "      <th>follower_count</th>\n",
              "      <th>following_count</th>\n",
              "      <th>is_business_account</th>\n",
              "      <th>is_private</th>\n",
              "      <th>...</th>\n",
              "      <th>business_category_name</th>\n",
              "      <th>overall_category_name</th>\n",
              "      <th>category_enum</th>\n",
              "      <th>is_verified_by_mv4b</th>\n",
              "      <th>is_regulated_c18</th>\n",
              "      <th>profile_pic_url</th>\n",
              "      <th>should_show_category</th>\n",
              "      <th>should_show_public_contacts</th>\n",
              "      <th>show_account_transparency_details</th>\n",
              "      <th>profile_picture_base64</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>beyazyakaliyiz</td>\n",
              "      <td>8634457436</td>\n",
              "      <td>Selam Beyaz Yakalƒ±</td>\n",
              "      <td>Beyaz yakalƒ±larƒ±n d√ºnyasƒ±na ho≈ügeldiniz üòÄüòÄüòÄ</td>\n",
              "      <td>Personal blog</td>\n",
              "      <td>None</td>\n",
              "      <td>1265</td>\n",
              "      <td>665</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>PERSONAL_BLOG</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://instagram.fist6-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>totalenergies_istasyonlari</td>\n",
              "      <td>7066643793</td>\n",
              "      <td>TotalEnergies IÃástasyonlarƒ±</td>\n",
              "      <td>TotalEnergies ƒ∞stasyonlarƒ± resmi Instagram hes...</td>\n",
              "      <td>Energy Company</td>\n",
              "      <td>None</td>\n",
              "      <td>28025</td>\n",
              "      <td>4</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>ENERGY_COMPANY</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>https://instagram.fsaw2-1.fna.fbcdn.net/v/t51....</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows √ó 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     username          id                    full_name  \\\n",
              "0              beyazyakaliyiz  8634457436           Selam Beyaz Yakalƒ±   \n",
              "1  totalenergies_istasyonlari  7066643793  TotalEnergies IÃástasyonlarƒ±   \n",
              "\n",
              "                                           biography   category_name  \\\n",
              "0        Beyaz yakalƒ±larƒ±n d√ºnyasƒ±na ho≈ügeldiniz üòÄüòÄüòÄ   Personal blog   \n",
              "1  TotalEnergies ƒ∞stasyonlarƒ± resmi Instagram hes...  Energy Company   \n",
              "\n",
              "  post_count follower_count following_count is_business_account is_private  \\\n",
              "0       None           1265             665                True      False   \n",
              "1       None          28025               4                True      False   \n",
              "\n",
              "   ... business_category_name overall_category_name   category_enum  \\\n",
              "0  ...                   None                  None   PERSONAL_BLOG   \n",
              "1  ...                   None                  None  ENERGY_COMPANY   \n",
              "\n",
              "  is_verified_by_mv4b is_regulated_c18  \\\n",
              "0               False            False   \n",
              "1               False            False   \n",
              "\n",
              "                                     profile_pic_url should_show_category  \\\n",
              "0  https://instagram.fist6-1.fna.fbcdn.net/v/t51....                 True   \n",
              "1  https://instagram.fsaw2-1.fna.fbcdn.net/v/t51....                 True   \n",
              "\n",
              "  should_show_public_contacts show_account_transparency_details  \\\n",
              "0                        True                              True   \n",
              "1                        True                              True   \n",
              "\n",
              "                              profile_picture_base64  \n",
              "0  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
              "1  /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...  \n",
              "\n",
              "[2 rows x 44 columns]"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test Profie Dataframe\n",
        "test_profile_df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Z5UY0eYLsoTr"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Improved preprocessing function\n",
        "def preprocess_text(text: str):\n",
        "    text = text.casefold()\n",
        "    \n",
        "    # Enhanced emoji handling\n",
        "    text = emoji.demojize(text) # Convert emojis to text\n",
        "    \n",
        "    # Better URL handling\n",
        "    text = re.sub(r'http[s]?://\\S+|www\\.\\S+', 'URL', text)\n",
        "    \n",
        "    # Enhanced hashtag handling - preserve important terms\n",
        "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
        "    \n",
        "    # Improved mention handling\n",
        "    text = re.sub(r'@(\\w+)', 'USER', text)\n",
        "    \n",
        "    # Handle numbers more intelligently\n",
        "    text = re.sub(r'\\d+k\\b', 'THOUSAND', text) # Handle 1k, 2k etc.\n",
        "    text = re.sub(r'\\d+m\\b', 'MILLION', text)\n",
        "    text = re.sub(r'\\d+(\\.\\d+)?', 'NUMBER', text)\n",
        "    \n",
        "    # Keep important punctuation\n",
        "    text = re.sub(r'[^\\w\\s!?.]', ' ', text)\n",
        "    \n",
        "    # Handle multiple spaces\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text\n",
        "\n",
        "def extract_additional_features(profile, posts):\n",
        "    features = {}\n",
        "    \n",
        "    # Profile-based features\n",
        "    follower_count = profile.get('follower_count', 0) or 0\n",
        "    following_count = profile.get('following_count', 0) or 0\n",
        "    features['follower_engagement_ratio'] = follower_count / (following_count + 1)\n",
        "    features['is_verified'] = int(profile.get('is_verified', False))\n",
        "    features['has_external_url'] = 1 if profile.get('external_url') else 0\n",
        "    \n",
        "    # Post-based features\n",
        "    post_likes = [p.get('like_count', 0) or 0 for p in posts]\n",
        "    features['avg_likes'] = np.mean(post_likes) if post_likes else 0\n",
        "    features['like_variance'] = np.var(post_likes) if post_likes else 0\n",
        "    features['engagement_rate'] = features['avg_likes'] / (follower_count + 1)\n",
        "    \n",
        "    return features\n",
        "\n",
        "# Initialize corpus and train usernames\n",
        "corpus = []\n",
        "train_usernames = []\n",
        "\n",
        "# Preprocess training data\n",
        "for username, posts in username2posts_train.items():\n",
        "    train_usernames.append(username)\n",
        "    \n",
        "    cleaned_captions = []\n",
        "    for post in posts:\n",
        "        post_caption = post.get(\"caption\", \"\")\n",
        "        if post_caption is None:\n",
        "            continue\n",
        "        \n",
        "        post_caption = preprocess_text(post_caption)\n",
        "        \n",
        "        if post_caption != \"\":\n",
        "            cleaned_captions.append(post_caption)\n",
        "    \n",
        "    # Joining the posts of each user with a separator (helps retain user-specific context)\n",
        "    user_post_captions = \" <SEP> \".join(cleaned_captions)\n",
        "    corpus.append(user_post_captions)\n",
        "\n",
        "# Update TF-IDF parameters for improved feature extraction\n",
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words=turkish_stopwords,\n",
        "    max_features=10000,         # Increased feature count for richer representation\n",
        "    ngram_range=(1, 2),         # Use unigrams and bigrams\n",
        "    sublinear_tf=True,          # Use logarithmic scaling for term frequency\n",
        "    max_df=0.7,                 # Ignore terms appearing in >70% of documents\n",
        "    min_df=3                    # Ignore terms appearing in <3 documents\n",
        ")\n",
        "\n",
        "# Fit the vectorizer\n",
        "vectorizer.fit(corpus)\n",
        "\n",
        "# Transform training data\n",
        "x_post_train = vectorizer.transform(corpus)\n",
        "\n",
        "# Assign labels to training data\n",
        "y_train = [username2_category.get(uname, \"NA\") for uname in train_usernames]\n",
        "\n",
        "# Preprocess test data\n",
        "test_usernames = []\n",
        "test_corpus = []\n",
        "\n",
        "for username, posts in username2posts_test.items():\n",
        "    test_usernames.append(username)\n",
        "    \n",
        "    cleaned_captions = []\n",
        "    for post in posts:\n",
        "        post_caption = post.get(\"caption\", \"\")\n",
        "        if post_caption is None:\n",
        "            continue\n",
        "        \n",
        "        post_caption = preprocess_text(post_caption)\n",
        "        \n",
        "        if post_caption != \"\":\n",
        "            cleaned_captions.append(post_caption)\n",
        "    \n",
        "    user_post_captions = \" <SEP> \".join(cleaned_captions)\n",
        "    test_corpus.append(user_post_captions)\n",
        "\n",
        "# Transform test data (do not fit again!)\n",
        "x_post_test = vectorizer.transform(test_corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "Q-BcPjw_39aP"
      },
      "outputs": [],
      "source": [
        "# Making sure everything is fine\n",
        "assert y_train.count(\"NA\") == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XP9ZrOIAvi9z",
        "outputId": "47634b8e-f5d0-4160-aab4-2cc60b4900e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['_________________________', 'abd', 'abdullah', ..., 'ÿ¨ŸÖŸÑÿ©', 'ÿπŸÑŸâ',\n",
              "       'ŸÅŸä'], dtype=object)"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_names = vectorizer.get_feature_names_out()\n",
        "feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "xa4v453o0Mo_",
        "outputId": "4787ecd7-ba6f-44aa-fa0a-cdaf39d33d3a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_________________________</th>\n",
              "      <th>abd</th>\n",
              "      <th>abdullah</th>\n",
              "      <th>abi</th>\n",
              "      <th>abiye</th>\n",
              "      <th>abone</th>\n",
              "      <th>about</th>\n",
              "      <th>about the</th>\n",
              "      <th>abs</th>\n",
              "      <th>ac</th>\n",
              "      <th>...</th>\n",
              "      <th>≈üƒ±klƒ±k</th>\n",
              "      <th>≈üƒ±klƒ±ƒüƒ±</th>\n",
              "      <th>–Ω–∞</th>\n",
              "      <th>–ø–æ</th>\n",
              "      <th>ÿßÿ≥ÿ∑ŸÜÿ®ŸàŸÑ</th>\n",
              "      <th>ÿ®Ÿá</th>\n",
              "      <th>ÿ™ÿ±ŸÉŸäÿß</th>\n",
              "      <th>ÿ¨ŸÖŸÑÿ©</th>\n",
              "      <th>ÿπŸÑŸâ</th>\n",
              "      <th>ŸÅŸä</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows √ó 10000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   _________________________  abd  abdullah  abi  abiye  abone  about  \\\n",
              "0                        0.0  0.0       0.0  0.0    0.0    0.0    0.0   \n",
              "1                        0.0  0.0       0.0  0.0    0.0    0.0    0.0   \n",
              "\n",
              "   about the  abs   ac  ...  ≈üƒ±klƒ±k  ≈üƒ±klƒ±ƒüƒ±   –Ω–∞   –ø–æ  ÿßÿ≥ÿ∑ŸÜÿ®ŸàŸÑ   ÿ®Ÿá  ÿ™ÿ±ŸÉŸäÿß  \\\n",
              "0        0.0  0.0  0.0  ...     0.0      0.0  0.0  0.0      0.0  0.0    0.0   \n",
              "1        0.0  0.0  0.0  ...     0.0      0.0  0.0  0.0      0.0  0.0    0.0   \n",
              "\n",
              "   ÿ¨ŸÖŸÑÿ©  ÿπŸÑŸâ   ŸÅŸä  \n",
              "0   0.0  0.0  0.0  \n",
              "1   0.0  0.0  0.0  \n",
              "\n",
              "[2 rows x 10000 columns]"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tfidf = pd.DataFrame(x_post_train.toarray(), columns=feature_names)\n",
        "df_tfidf.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1i9xO_ZX1NXC",
        "outputId": "15c76222-630d-4c3c-9ba5-96a44af78a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2741, 10000)\n"
          ]
        }
      ],
      "source": [
        "print(df_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "ehUT3JSFz7yo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(df_tfidf, y_train, test_size=0.2, stratify=y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipJX5GBZ1efb",
        "outputId": "dde21a01-9349-44de-cc16-3605f332f756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2192, 10000)\n",
            "(549, 10000)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape)\n",
        "\n",
        "print(x_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'C': 10, 'class_weight': 'balanced', 'solver': 'liblinear'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1.0, 10],\n",
        "    'solver': ['liblinear', 'lbfgs'],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "# Grid search for Logistic Regression\n",
        "grid_search = GridSearchCV(\n",
        "    LogisticRegression(max_iter=500),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best parameters:\", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khu0eryhNZNN"
      },
      "source": [
        "# Naive Base Classifier\n",
        "\n",
        "### Now we can pass the numerical values to a classifier, Let's try Naive Base!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "rdHIvFrSCMZj",
        "outputId": "043e1aaf-0e8b-4b20-8a32-c27298d253ac"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=500,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=500,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=10, class_weight='balanced', max_iter=500,\n",
              "                   solver='liblinear')"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train a Logistic Regression model with balanced class weights\n",
        "model = LogisticRegression(\n",
        "    class_weight='balanced', \n",
        "    max_iter=500, \n",
        "    solver='liblinear', \n",
        "    penalty='l2', \n",
        "    C=10\n",
        ")\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyY9aFtGDrAj",
        "outputId": "e44c466d-6bf0-4556-ad4b-7c7111ad2835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9908759124087592\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "                 art       0.99      0.99      0.99       153\n",
            "       entertainment       1.00      0.99      0.99       258\n",
            "             fashion       0.99      0.99      0.99       239\n",
            "                food       0.98      1.00      0.99       409\n",
            "              gaming       1.00      1.00      1.00        10\n",
            "health and lifestyle       1.00      0.98      0.99       402\n",
            "    mom and children       0.99      1.00      1.00       119\n",
            "              sports       1.00      1.00      1.00        90\n",
            "                tech       0.99      1.00      0.99       277\n",
            "              travel       0.99      0.99      0.99       235\n",
            "\n",
            "            accuracy                           0.99      2192\n",
            "           macro avg       0.99      0.99      0.99      2192\n",
            "        weighted avg       0.99      0.99      0.99      2192\n",
            "\n",
            "Accuracy: 0.6903460837887068\n",
            "\n",
            "Classification Report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "                 art       0.46      0.32      0.37        38\n",
            "       entertainment       0.47      0.54      0.50        65\n",
            "             fashion       0.69      0.78      0.73        60\n",
            "                food       0.93      0.89      0.91       102\n",
            "              gaming       0.00      0.00      0.00         3\n",
            "health and lifestyle       0.62      0.73      0.67       100\n",
            "    mom and children       0.88      0.50      0.64        30\n",
            "              sports       0.84      0.70      0.76        23\n",
            "                tech       0.70      0.75      0.73        69\n",
            "              travel       0.70      0.64      0.67        59\n",
            "\n",
            "            accuracy                           0.69       549\n",
            "           macro avg       0.63      0.59      0.60       549\n",
            "        weighted avg       0.70      0.69      0.69       549\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Validation Data\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_train_pred = model.predict(x_train)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_train, y_train_pred, zero_division=0))\n",
        "\n",
        "\n",
        "y_val_pred = model.predict(x_val)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_val_pred, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU6aALFaCMkd",
        "outputId": "83913a4f-45bc-4e1a-e069-06d452f31255"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ozhotelstr\n",
            "elleturkiye\n",
            "sozerinsaatorhangazi\n",
            "sanliurfapiazzaavym\n",
            "rusanozden\n",
            "*****\n",
            "['ozhotelstr', 'elleturkiye', 'sozerinsaatorhangazi', 'sanliurfapiazzaavym', 'rusanozden']\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the testing directory\n",
        "testing_dir = os.path.join(data_dir, 'testing')\n",
        "\n",
        "# File path for 'test-classification-round1.dat'\n",
        "test_data_path = os.path.join(testing_dir, 'test-classification-round1.dat')\n",
        "\n",
        "# Step 2: Preview First 5 Lines of the Test File\n",
        "with open(test_data_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for i, line in enumerate(fh):\n",
        "        print(line.strip())\n",
        "        if i == 4:  # Print only the first 5 lines\n",
        "            break\n",
        "\n",
        "print(\"*****\")\n",
        "\n",
        "# Step 3: Extract Usernames from Test Data\n",
        "test_unames = []\n",
        "with open(test_data_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for line in fh:\n",
        "        test_unames.append(line.strip())\n",
        "\n",
        "# Step 4: Verify Output\n",
        "print(test_unames[:5])  # Display the first 5 usernames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqLF4LN8GqKm",
        "outputId": "779e32d6-a7be-4a03-d6c9-7f601b68cdbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "screenname\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_________________________</th>\n",
              "      <th>abd</th>\n",
              "      <th>abdullah</th>\n",
              "      <th>abi</th>\n",
              "      <th>abiye</th>\n",
              "      <th>abone</th>\n",
              "      <th>about</th>\n",
              "      <th>about the</th>\n",
              "      <th>abs</th>\n",
              "      <th>ac</th>\n",
              "      <th>...</th>\n",
              "      <th>≈üƒ±klƒ±k</th>\n",
              "      <th>≈üƒ±klƒ±ƒüƒ±</th>\n",
              "      <th>–Ω–∞</th>\n",
              "      <th>–ø–æ</th>\n",
              "      <th>ÿßÿ≥ÿ∑ŸÜÿ®ŸàŸÑ</th>\n",
              "      <th>ÿ®Ÿá</th>\n",
              "      <th>ÿ™ÿ±ŸÉŸäÿß</th>\n",
              "      <th>ÿ¨ŸÖŸÑÿ©</th>\n",
              "      <th>ÿπŸÑŸâ</th>\n",
              "      <th>ŸÅŸä</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.02918</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows √ó 10000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   _________________________      abd  abdullah  abi  abiye  abone  about  \\\n",
              "0                        0.0  0.00000       0.0  0.0    0.0    0.0    0.0   \n",
              "1                        0.0  0.02918       0.0  0.0    0.0    0.0    0.0   \n",
              "\n",
              "   about the  abs   ac  ...  ≈üƒ±klƒ±k  ≈üƒ±klƒ±ƒüƒ±   –Ω–∞   –ø–æ  ÿßÿ≥ÿ∑ŸÜÿ®ŸàŸÑ   ÿ®Ÿá  ÿ™ÿ±ŸÉŸäÿß  \\\n",
              "0        0.0  0.0  0.0  ...     0.0      0.0  0.0  0.0      0.0  0.0    0.0   \n",
              "1        0.0  0.0  0.0  ...     0.0      0.0  0.0  0.0      0.0  0.0    0.0   \n",
              "\n",
              "   ÿ¨ŸÖŸÑÿ©  ÿπŸÑŸâ   ŸÅŸä  \n",
              "0   0.0  0.0  0.0  \n",
              "1   0.0  0.0  0.0  \n",
              "\n",
              "[2 rows x 10000 columns]"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test = []\n",
        "\n",
        "for uname in test_unames:\n",
        "  try:\n",
        "    index = test_usernames.index(uname)\n",
        "    x_test.append(x_post_test[index].toarray()[0])\n",
        "  except Exception as e:\n",
        "    try:\n",
        "      index = train_usernames.index(uname)\n",
        "      x_test.append(x_post_train[index].toarray()[0])\n",
        "    except Exception as e:\n",
        "      print(uname)\n",
        "\n",
        "\n",
        "print(test_unames.remove(\"screenname\"))\n",
        "\n",
        "df_test = pd.DataFrame(np.array(x_test), columns=feature_names)\n",
        "df_test.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "gUsUQtpMKTse"
      },
      "outputs": [],
      "source": [
        "test_pred = model.predict(df_test)\n",
        "\n",
        "output = dict()\n",
        "for index, uname in enumerate(test_unames):\n",
        "  output[uname] = test_pred[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "W-NJSnyxIrw4"
      },
      "outputs": [],
      "source": [
        "with open(\"output.json\", \"w\") as of:\n",
        "  json.dump(output, of, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC7KXsQZL7Kp"
      },
      "source": [
        "# Like Count Prediction\n",
        "\n",
        "\n",
        "Here, we use the average like_count of the user's previous posts to predict each post's like_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "nolpagasSuBq"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "def extract_post_features(post):\n",
        "    \"\"\"Extract comprehensive features from a post\"\"\"\n",
        "    timestamp = pd.to_datetime(post.get('timestamp', None))\n",
        "    caption = post.get('caption', '')\n",
        "    \n",
        "    features = {\n",
        "        # Temporal features\n",
        "        'hour': timestamp.hour if timestamp else 0,\n",
        "        'day_of_week': timestamp.dayofweek if timestamp else 0,\n",
        "        'is_weekend': int(timestamp.dayofweek >= 5) if timestamp else 0,\n",
        "        \n",
        "        # Content features\n",
        "        'caption_length': len(caption) if caption else 0,\n",
        "        'has_caption': int(bool(caption)),\n",
        "        'emoji_count': sum(1 for c in caption if c in emoji.EMOJI_DATA) if caption else 0,\n",
        "        'hashtag_count': caption.count('#') if caption else 0,\n",
        "        'mention_count': caption.count('@') if caption else 0,\n",
        "        \n",
        "        # Engagement features\n",
        "        'comments_count': post.get('comments_count', 0) or 0,\n",
        "        'is_video': int(post.get('media_type', '') == 'VIDEO'),\n",
        "        'is_carousel': int(post.get('media_type', '') == 'CAROUSEL_ALBUM'),\n",
        "    }\n",
        "    \n",
        "    return features\n",
        "\n",
        "def extract_profile_features(profile):\n",
        "    \"\"\"Extract comprehensive features from a profile\"\"\"\n",
        "    bio = profile.get('biography', '')\n",
        "    \n",
        "    return {\n",
        "        'follower_count': profile.get('follower_count', 0) or 0,\n",
        "        'following_count': profile.get('following_count', 0) or 0,\n",
        "        'post_count': profile.get('post_count', 0) or 0,\n",
        "        'is_verified': int(profile.get('is_verified', False)),\n",
        "        'is_business': int(profile.get('is_business_account', False)),\n",
        "        'bio_length': len(bio) if bio else 0,\n",
        "        'has_external_url': int(bool(profile.get('external_url', ''))),\n",
        "        'engagement_ratio': (profile.get('follower_count', 0) or 0) / \n",
        "                          (profile.get('following_count', 1) or 1)\n",
        "    }\n",
        "\n",
        "def predict_like_count(username, current_post=None):\n",
        "    \"\"\"Predict like count using advanced regression model\"\"\"\n",
        "    posts = username2posts_train.get(username) or username2posts_test.get(username)\n",
        "    profile = username2profile_train.get(username) or username2profile_test.get(username)\n",
        "    \n",
        "    if not posts or not profile:\n",
        "        return 0\n",
        "        \n",
        "    # Prepare training data\n",
        "    X = []\n",
        "    y = []\n",
        "    \n",
        "    for post in posts:\n",
        "        if current_post and post['id'] == current_post['id']:\n",
        "            continue\n",
        "            \n",
        "        post_features = extract_post_features(post)\n",
        "        profile_features = extract_profile_features(profile)\n",
        "        \n",
        "        # Combine features\n",
        "        features = {**post_features, **profile_features}\n",
        "        X.append(features)\n",
        "        y.append(post.get('like_count', 0) or 0)\n",
        "    \n",
        "    if not X:\n",
        "        return 0\n",
        "    \n",
        "    # Convert to DataFrame and handle missing values\n",
        "    X_df = pd.DataFrame(X)\n",
        "    X_df = X_df.fillna(0)\n",
        "    \n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_df)\n",
        "    \n",
        "    # Transform target variable (log transformation for better handling of skewed data)\n",
        "    y = np.log1p(y)\n",
        "    \n",
        "    # Train model with optimized parameters\n",
        "    model = XGBRegressor(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        min_child_weight=3,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=0.1,\n",
        "        reg_lambda=1,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    model.fit(X_scaled, y)\n",
        "    \n",
        "    # Predict for current post\n",
        "    if current_post:\n",
        "        features = {**extract_post_features(current_post), **extract_profile_features(profile)}\n",
        "        X_pred = pd.DataFrame([features])\n",
        "        X_pred = X_pred.fillna(0)\n",
        "        X_pred_scaled = scaler.transform(X_pred)\n",
        "        \n",
        "        # Transform prediction back to original scale\n",
        "        prediction = np.expm1(model.predict(X_pred_scaled)[0])\n",
        "        return int(max(0, prediction))\n",
        "    \n",
        "    # Return mean if no current post (for initialization)\n",
        "    return int(np.mean(np.expm1(y)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "ZNWTjLZ6XAuj"
      },
      "outputs": [],
      "source": [
        "def log_mse_like_counts(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculate the Log Mean Squared Error (Log MSE) for like counts (log(like_count + 1)).\n",
        "\n",
        "  Parameters:\n",
        "  - y_true: array-like, actual like counts\n",
        "  - y_pred: array-like, predicted like counts\n",
        "\n",
        "  Returns:\n",
        "  - log_mse: float, Log Mean Squared Error\n",
        "  \"\"\"\n",
        "  # Ensure inputs are numpy arrays\n",
        "  y_true = np.array(y_true)\n",
        "  y_pred = np.array(y_pred)\n",
        "\n",
        "  # Log transformation: log(like_count + 1)\n",
        "  log_y_true = np.log1p(y_true)\n",
        "  log_y_pred = np.log1p(y_pred)\n",
        "\n",
        "  # Compute squared errors\n",
        "  squared_errors = (log_y_true - log_y_pred) ** 2\n",
        "\n",
        "  # Return the mean of squared errors\n",
        "  return np.mean(squared_errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1jETdAuXA0H",
        "outputId": "871164d0-74fb-49cd-ea77-b8a3e0793e81"
      },
      "outputs": [],
      "source": [
        "# Train Dataset evaluation\n",
        "\n",
        "y_like_count_train_true = []\n",
        "y_like_count_train_pred = []\n",
        "for uname, posts in username2posts_train.items():\n",
        "  for post in posts:\n",
        "    pred_val = predict_like_count(uname, post)\n",
        "    true_val = post.get(\"like_count\", 0)\n",
        "    if true_val is None:\n",
        "      true_val = 0\n",
        "\n",
        "    y_like_count_train_true.append(true_val)\n",
        "    y_like_count_train_pred.append(pred_val)\n",
        "\n",
        "print(f\"Log MSE Train= {log_mse_like_counts(y_like_count_train_true, y_like_count_train_pred)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "F02V1wO-WBMV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed data saved to: c:\\Users\\itsmm\\OneDrive\\Desktop\\CS412\\CS412-InstagramInfluencersAnalysis\\data\\output\\test-regression-round1.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define File Paths Dynamically\n",
        "# Get the current notebook directory\n",
        "current_notebook_dir = os.getcwd()\n",
        "\n",
        "# Get the repo directory (assuming notebooks are inside the \"notebooks\" folder)\n",
        "repo_dir = os.path.abspath(os.path.join(current_notebook_dir, '..'))\n",
        "\n",
        "# Get the data directory\n",
        "data_dir = os.path.join(repo_dir, 'data')\n",
        "\n",
        "# Get the testing directory\n",
        "testing_dir = os.path.join(data_dir, 'testing')\n",
        "\n",
        "# File path for 'test-regression-round1.jsonl'\n",
        "test_dataset_path = os.path.join(testing_dir, 'test-regression-round1.jsonl')\n",
        "\n",
        "# File path for output\n",
        "output_dir = os.path.join(data_dir, 'output')\n",
        "os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
        "output_file_path = os.path.join(output_dir, 'test-regression-round1.jsonl')\n",
        "\n",
        "# Step 2: Process the Test Dataset\n",
        "to_predict_like_counts_usernames = []\n",
        "output_list = []\n",
        "\n",
        "with open(test_dataset_path, \"rt\", encoding=\"utf-8\") as fh:\n",
        "    for line in fh:\n",
        "        sample = json.loads(line)\n",
        "\n",
        "        # Perform prediction\n",
        "        pred_val = predict_like_count(sample[\"username\"])  # Ensure `predict_like_count` is defined\n",
        "        sample[\"like_count\"] = int(pred_val)\n",
        "        output_list.append(sample)\n",
        "\n",
        "# Step 3: Save the Output to a File\n",
        "with open(output_file_path, \"wt\", encoding=\"utf-8\") as of:\n",
        "    json.dump(output_list, of)\n",
        "\n",
        "# Step 4: Output Verification\n",
        "print(f\"Processed data saved to: {output_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blI2SqvvvOF8",
        "outputId": "fe1e72e3-3ad0-486d-d054-3e90e8c66669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'caption': 'KOZA 2023 2.si Damla‚Äônƒ±n koleksiyonu, Latincede ‚ÄòMemento Mori‚Äô '\n",
            "             'olarak bilinen ‚Äò√∂l√ºml√º olduƒüunu hatƒ±rla‚Äô anlamƒ±ndaki ifadeden '\n",
            "             'esinleniyor. Koleksiyon, hayatƒ±n ve √∂l√ºm√ºn, para, i≈ü√ßi, kral ve '\n",
            "             'krali√ße kavramlarƒ± √ºzerinden yaratƒ±cƒ± g√∂r√ºn√ºmlerle bir araya '\n",
            "             'getirilmesini ama√ßlƒ±yor. √ñl√ºm sembollerinden esinlenen desenler '\n",
            "             'kullanan Damla, ‚Äúkaƒüƒ±t par√ßasƒ±ndan ibaret olmak‚Äù kavramƒ±nƒ± '\n",
            "             'vurguluyor. Koleksiyon, ya≈üamƒ±n ve √∂l√ºm√ºn aynƒ± anda ifade '\n",
            "             'edilmesini hedefliyor; kƒ±rmƒ±zƒ± ve mavi ƒ±≈üƒ±klarla veya '\n",
            "             'g√∂zl√ºklerle g√∂r√ºlen hologram efekti kullanƒ±larak bu konsept '\n",
            "             'sahneye ta≈üƒ±nƒ±yor. Kƒ±rmƒ±zƒ± renk √∂l√ºm√º, mavi ise ya≈üamƒ± '\n",
            "             'simgeliyor. Koleksiyon, ofis giyimlerinden esinlenerek '\n",
            "             'kravatlar, g√∂mlekler ve evrak √ßantalarƒ± i√ßeriyor. Klasik sivri '\n",
            "             'burun √ßizmelerin √ºzerine spor ayakkabƒ±larƒ±n √ºst y√ºzeyi '\n",
            "             'yerle≈ütirilerek, i≈ü d√ºnyasƒ±nƒ±n ko≈üu≈üturmasƒ± ve cenaze '\n",
            "             'temalarƒ±nƒ±n aynƒ± anda ifade edilmesi ama√ßlanƒ±yor. Para kazanma '\n",
            "             'arzusu, kƒ±rmƒ±zƒ± zambak desenleri ve b√ºy√ºk m√ºcevher g√∂r√ºn√ºmleri '\n",
            "             'ile koleksiyon tamamlanƒ±yor.\\n'\n",
            "             '\\n'\n",
            "             'Tebrikler Damla!\\n'\n",
            "             '\\n'\n",
            "             '#GencModaTasarimcilari #Koza2023 #KozaYarismasi '\n",
            "             '#TasarimYarismasi #Moda #Fashion #ModaTasarƒ±mƒ±',\n",
            "  'comments_count': 2,\n",
            "  'id': '18144550534306740',\n",
            "  'like_count': 158,\n",
            "  'media_type': 'CAROUSEL_ALBUM',\n",
            "  'media_url': 'https://scontent-sof1-1.cdninstagram.com/v/t51.29350-15/397997154_1016992459537522_4925783512176260397_n.jpg?_nc_cat=106&ccb=1-7&_nc_sid=c4dd86&_nc_ohc=7V_eObkFeK4AX-LMtsK&_nc_ht=scontent-sof1-1.cdninstagram.com&edm=AL-3X8kEAAAA&oh=00_AfDEqDhzaTO3ezV-veT6cJFCOcAEyeVzHR6si9n33N6G5A&oe=6551B6B9',\n",
            "  'timestamp': '2023-11-02 15:49:22',\n",
            "  'username': 'kozayarismasi'},\n",
            " {'caption': 'T√ºm T√ºrkiye ve Avrupa‚Äôya sevkiyatlarƒ±mƒ±z aralƒ±ksƒ±z devam ediyor! '\n",
            "             'Aracƒ±mƒ±z Bursa‚Äôdan Ordu‚Äôya m√º≈üterimizin √ºr√ºnleri i√ßin yola '\n",
            "             '√ßƒ±kƒ±yor.\\n'\n",
            "             '\\n'\n",
            "             'üëâTuna Mah. Etibank Cad. No:134 Osmangazi/BURSA\\n'\n",
            "             '\\n'\n",
            "             'www.celikbeymobilya.com sitemizden t√ºm modelleri '\n",
            "             'inceleyebilirsiniz. \\n'\n",
            "             '\\n'\n",
            "             '#bursa #almanya #fransa',\n",
            "  'comments_count': 0,\n",
            "  'id': '17995331788956693',\n",
            "  'like_count': 99,\n",
            "  'media_type': 'VIDEO',\n",
            "  'media_url': 'https://scontent-sof1-2.cdninstagram.com/o1/v/t16/f1/m82/BF4767CB85BDFB8ADCCCA8F15B8C20B5_video_dashinit.mp4?efg=eyJ2ZW5jb2RlX3RhZyI6InZ0c192b2RfdXJsZ2VuLmNsaXBzLnVua25vd24tQzMuNzIwLmRhc2hfYmFzZWxpbmVfMV92MSJ9&_nc_ht=scontent-sof1-2.cdninstagram.com&_nc_cat=110&vs=1259525061418244_1441854817&_nc_vs=HBksFQIYT2lnX3hwdl9yZWVsc19wZXJtYW5lbnRfcHJvZC9CRjQ3NjdDQjg1QkRGQjhBRENDQ0E4RjE1QjhDMjBCNV92aWRlb19kYXNoaW5pdC5tcDQVAALIAQAVAhg6cGFzc3Rocm91Z2hfZXZlcnN0b3JlL0dBRWdfaFZfcDVCYk5HZ0NBQTlzVURvZW5mZ3FicV9FQUFBRhUCAsgBACgAGAAbAYgHdXNlX29pbAExFQAAJvS3uOiQ0P8%2FFQIoAkMzLBdAJO%2Bdsi0OVhgSZGFzaF9iYXNlbGluZV8xX3YxEQB1AAA%3D&ccb=9-4&oh=00_AfAm22JssMPaUlQe3rpYsFWBhFb5mUgolTCdhV0Xgm4AnA&oe=6556A482&_nc_sid=1d576d&_nc_rid=cd9a998e44',\n",
            "  'timestamp': '2023-08-19 13:46:02',\n",
            "  'username': 'celikbeymobilya'},\n",
            " {'caption': 'ü§©\\n'\n",
            "             '\\n'\n",
            "             '.\\n'\n",
            "             '.\\n'\n",
            "             'Daha Fazlasƒ± ƒ∞√ßin Beƒüenmeyi ve Takip Etmeyi Unutmayƒ±n\\n'\n",
            "             '.\\n'\n",
            "             'girisimci_muhendis ‚úÖ\\n'\n",
            "             '.\\n'\n",
            "             'üì£Bu Bilgi Hakkƒ±nda Ne D√º≈ü√ºn√ºyorsunuz.\\n'\n",
            "             '.\\n'\n",
            "             '‚úÖG√∂rmesini ƒ∞stediƒüin Arkada≈üƒ±nƒ± Etiketle.\\n'\n",
            "             '.\\n'\n",
            "             'üîîG√∂nderi Bildirimlerini A√ßarak, Bilgileri Anƒ±nda '\n",
            "             '√ñƒürenebilirsiniz.\\n'\n",
            "             '\\n'\n",
            "             '.\\n'\n",
            "             '\\n'\n",
            "             'Source: Unknown\\n'\n",
            "             'Dm for Credit or removal\\n'\n",
            "             '.\\n'\n",
            "             '.............................................................\\n'\n",
            "             'All rights and credits reserved to the respective owner(s). If '\n",
            "             'you are the main copyright owner rather than the one mentioned '\n",
            "             'here of this content, contact me to claim credit or content '\n",
            "             'removal',\n",
            "  'comments_count': 75,\n",
            "  'id': '18302703232191518',\n",
            "  'like_count': 1224,\n",
            "  'media_type': 'VIDEO',\n",
            "  'media_url': None,\n",
            "  'timestamp': '2023-10-02 06:53:33',\n",
            "  'username': 'girisimci_muhendis'}]\n"
          ]
        }
      ],
      "source": [
        "# output_list first 3 items\n",
        "pprint(output_list[:3])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
